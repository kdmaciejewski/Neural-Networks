{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krzys\\desktop\\pythonproject\\againterpreter\\lib\\site-packages\\pandas\\core\\generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "from cmath import exp\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "X = heart_disease.data.features\n",
    "Y = heart_disease.data.targets\n",
    "X.fillna({'ca': X['ca'].median(), 'thal': X['thal'].mode()[0]}, inplace=True)\n",
    "\n",
    "for index, row in Y.iterrows():\n",
    "    if row[0] != 0:\n",
    "        row[0] = 1 #jeżeli nie ma klasy 0 to ma klasę 1\n",
    "\n",
    "y = Y.to_numpy()\n",
    "X = (X-X.min())/(X.max()-X.min())\n",
    "x = X.to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [49.817166174553414, 50.20830670613731, 49.99049552151656, 49.909653399882906, 50.02847021805165, 49.86938639292833, 49.94778162916356, 49.831188148707064, 50.112118078879774, 50.07972260889731, 50.02660056463222, 49.92605749459056, 49.94957701380815, 50.02114314862527]}, {'weights': [50.06322138801076, 50.22832032814158, 49.903662577820064, 50.12324676104338, 49.89283525146773, 49.998338283517825, 50.11154893234289, 49.939122332861366, 49.852334298456725, 50.025859942906415, 50.327921316915806, 50.17773789818495, 50.01855053470606, 50.0429387316317]}, {'weights': [49.99236655850847, 49.933634794609475, 50.15157120950434, 49.91448946540333, 49.908432939015285, 49.93521955535791, 49.92992983460995, 50.032289288888215, 50.00980561334021, 50.06759532107658, 49.89296352594946, 50.11217400175912, 49.856436774621756, 49.892720325047996]}, {'weights': [50.05186548312849, 49.98090832343655, 49.88558163743578, 50.10857790579012, 49.81972168361326, 50.01564521483046, 49.96722209687791, 50.09311949224784, 50.05751899765097, 49.94425939224328, 50.11658541410911, 50.070010573062156, 49.99192048468063, 50.11867845083773]}]\n",
      "\n",
      "[{'weights': [49.820609627907835, 50.02553264769525, 50.006834984836765, 49.70721080606914, 49.90598491194942]}, {'weights': [49.94506968212848, 50.112596342182435, 50.11219902637214, 50.159343681443346, 49.98864717583051]}]\n",
      "\n",
      "[{'weights': [49.89401853627108, 50.103083621151654, 50.03094102118038]}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import uniform\n",
    "\n",
    "# def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "# \tnetwork = list()\n",
    "# \t# +1 jest bo bias\n",
    "# \thidden_layer = [{'weights':[uniform(1, 100) for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "# \tnetwork.append(hidden_layer)\n",
    "# \toutput_layer = [{'weights':[uniform(1, 100) for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "# \tnetwork.append(output_layer)\n",
    "# \treturn network\n",
    "\n",
    "# def initialize_network(n_inputs, hidden_layers, n_outputs):\n",
    "#     network = []\n",
    "#\n",
    "#     for num_neurons in hidden_layers:\n",
    "#         hidden_layer = [{'weights': [uniform(1, 100) for i in range(n_inputs + 1)]} for i in range(num_neurons)]\n",
    "#         network.append(hidden_layer)\n",
    "#         n_inputs = num_neurons\n",
    "#\n",
    "#     output_layer = [{'weights': [uniform(1, 100) for i in range(n_inputs + 1)]} for i in range(n_outputs)]\n",
    "#     network.append(output_layer)\n",
    "#\n",
    "#     return network\n",
    "def initialize_network(n_inputs, hidden_layers, n_outputs, std_dev, mean):\n",
    "    network = []\n",
    "    for num_neurons in hidden_layers:\n",
    "        hidden_layer = [{'weights': list(np.random.normal(mean, std_dev, n_inputs + 1))} for i in range(num_neurons)]\n",
    "        network.append(hidden_layer)\n",
    "        n_inputs = num_neurons\n",
    "\n",
    "    output_layer = [{'weights': list(np.random.normal(mean, std_dev, n_inputs + 1))} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "seed(1)\n",
    "n_inputs = 13\n",
    "hidden_layers = [4,2]\n",
    "n_outputs = 1\n",
    "std_deviation = 0.1\n",
    "network = initialize_network(n_inputs, hidden_layers, n_outputs, std_deviation, 50)\n",
    "# network = initialize_network(13, [4, 3], 1, [0.1, 0.2])\n",
    "for layer in network:\n",
    "\tprint(layer) # tutaj jest o 1 więcej wag bo bias\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#ostatnia waga jest biasem\n",
    "def activate(weights, inputs):\n",
    "\tactivation = weights[-1]\t#biasa nie mnożymy\n",
    "\tfor i in range(len(weights)-1):\n",
    "\t\tactivation += weights[i] * inputs[i]\t#sumujemy argument do sigmoida\n",
    "\treturn activation\n",
    "\n",
    "def transfer(activation):\n",
    "\treturn 1.0 / (1.0 + exp(-activation/200))\t# sigmoid\n",
    "\n",
    "# pochodna sigmoida\n",
    "def transfer_derivative(output):\n",
    "\treturn (output/200) * (1.0 - output/200)\n",
    "\n",
    "def loss_fun(y, y_pred):\n",
    "    epsilon = 1e-15  # zapobieganie log(0)\n",
    "    loss = - (y * np.log(y_pred + epsilon) + (1 - y) * np.log(1 - y_pred + epsilon))\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def forward_propagate(network, row):\n",
    "\tinputs = row\n",
    "\tfor layer in network:\n",
    "\t\tnew_inputs = []\n",
    "\t\tfor neuron in layer:\t# bierzemy wagi danego neuronu\n",
    "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
    "\t\t\tneuron['output'] = transfer(activation)\t# wartość wyjściowa neurona zapisana na potem\n",
    "\t\t\tnew_inputs.append(neuron['output'])\n",
    "\t\tinputs = new_inputs\t\t# przechodzi jako nowy wkład kolejnej warstwy\n",
    "\treturn inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def backward_propagate_error(network, expected):\n",
    "\tfor i in reversed(range(len(network))): # idziemy od końca\n",
    "\t\tlayer = network[i]\n",
    "\t\terrors = list()\n",
    "\t\t#jeżeli to nie jest ostatnia warstwa (zaczynamy i tak od ostatniej)\n",
    "\t\tif i != len(network)-1:\n",
    "\t\t\tfor j in range(len(layer)):\t#przechodzimy po neuronach warstwy\n",
    "\t\t\t\terror = 0.0\n",
    "\t\t\t\tfor neuron in network[i + 1]:\n",
    "\t\t\t\t\t# pobieramy wagi łączące ten neuron z prawym (z tablicy neurona następnej warstwy) i zapisujemy error\n",
    "\t\t\t\t\t# ponieważ my tutaj jesteśmy w poprzedniej warstwie (bardziej prawej) to\n",
    "\t\t\t\t\t# neuron delta już jest policzony\n",
    "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
    "\t\t\t\terrors.append(error)\n",
    "\t\t#jeżeli to ostatnia (czyli pierwsza) warstwa to liczę błąd\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\tneuron = layer[j]\n",
    "\t\t\t\terrors.append(neuron['output'] - expected[j])\n",
    "\t\t#obliczenia w danej warstwie, przechodzimy ją aktualizując wartości błędu neuronu\n",
    "\t\t# przy pomocy pochodnej\n",
    "\t\tfor j in range(len(layer)):\n",
    "\t\t\tneuron = layer[j]\n",
    "\t\t\t# delta = błąd dla każdego neuronu razy pochodna\n",
    "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def update_weights(network, row, l_rate):\n",
    "\tfor i in range(len(network)):\n",
    "\t\tinputs = row[:-1] # bo ostatni jest bias\n",
    "\t\tif i != 0:\t#jeżeli to nie jest pierwsza warstwa updatujemy wagi od lewej teraz\n",
    "\t\t\t#output poprzedniej warstwy to input\n",
    "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "\t\tfor neuron in network[i]:\n",
    "\t\t\tfor j in range(len(inputs)):\n",
    "\t\t\t\t#aktualizacja wag w tablicy neuronu danej warstwy\n",
    "\t\t\t\tneuron['weights'][j] -= l_rate * neuron['delta'] * inputs[j]\n",
    "\t\t\t#aktualizacja biasu\n",
    "\t\t\tneuron['weights'][-1] -= l_rate * neuron['delta']\n",
    "\n",
    "\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "\tavg_loss = 0\n",
    "\tfor epoch in range(n_epoch):\n",
    "\t\tsum_error = 0\n",
    "\t\tfor row in train:\n",
    "\t\t\texpected = [0 for i in range(n_outputs)]\n",
    "\t\t\texpected[0] = int(row[-1])\n",
    "\t\t\toutputs = forward_propagate(network, row)\n",
    "\t\t\tsum_error += loss_fun(int(row[-1]), outputs[0]) #na sztywno pierwszy element żeby nie komplikować\n",
    "\t\t\tbackward_propagate_error(network, expected)\n",
    "\t\t\tupdate_weights(network, row, l_rate)\n",
    "\n",
    "\t\tavg_loss = sum_error/len(train)\n",
    "\t\tprint(f\"Epoka: {epoch}, avg_loss: {avg_loss}\")\n",
    "\n",
    "\treturn avg_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka: 0, avg_loss: (1.4283482611413534+0j)\n",
      "Epoka: 1, avg_loss: (1.4249216277525745+0j)\n",
      "Epoka: 2, avg_loss: (1.421504525920841+0j)\n",
      "Epoka: 3, avg_loss: (1.4180970098096721+0j)\n",
      "Epoka: 4, avg_loss: (1.4146991332262921+0j)\n",
      "Epoka: 5, avg_loss: (1.411310949603949+0j)\n",
      "Epoka: 6, avg_loss: (1.4079325119842576+0j)\n",
      "Epoka: 7, avg_loss: (1.4045638729996315+0j)\n",
      "Epoka: 8, avg_loss: (1.4012050848557889+0j)\n",
      "Epoka: 9, avg_loss: (1.3978561993143432+0j)\n",
      "Epoka: 10, avg_loss: (1.3945172676755215+0j)\n",
      "Epoka: 11, avg_loss: (1.3911883407609975+0j)\n",
      "Epoka: 12, avg_loss: (1.3878694688968805+0j)\n",
      "Epoka: 13, avg_loss: (1.3845607018968484+0j)\n",
      "Epoka: 14, avg_loss: (1.3812620890454688+0j)\n",
      "Epoka: 15, avg_loss: (1.3779736790816899+0j)\n",
      "Epoka: 16, avg_loss: (1.3746955201825597+0j)\n",
      "Epoka: 17, avg_loss: (1.3714276599471364+0j)\n",
      "Epoka: 18, avg_loss: (1.3681701453806512+0j)\n",
      "Epoka: 19, avg_loss: (1.3649230228789093+0j)\n",
      "Epoka: 20, avg_loss: (1.3616863382129418+0j)\n",
      "Epoka: 21, avg_loss: (1.358460136513941+0j)\n",
      "Epoka: 22, avg_loss: (1.3552444622584692+0j)\n",
      "Epoka: 23, avg_loss: (1.3520393592539797+0j)\n",
      "Epoka: 24, avg_loss: (1.348844870624628+0j)\n",
      "Epoka: 25, avg_loss: (1.3456610387974188+0j)\n",
      "Epoka: 26, avg_loss: (1.3424879054886631+0j)\n",
      "Epoka: 27, avg_loss: (1.339325511690807+0j)\n",
      "Epoka: 28, avg_loss: (1.3361738976595803+0j)\n",
      "Epoka: 29, avg_loss: (1.333033102901519+0j)\n",
      "Epoka: 30, avg_loss: (1.3299031661618659+0j)\n",
      "Epoka: 31, avg_loss: (1.326784125412837+0j)\n",
      "Epoka: 32, avg_loss: (1.3236760178422682+0j)\n",
      "Epoka: 33, avg_loss: (1.3205788798426752+0j)\n",
      "Epoka: 34, avg_loss: (1.3174927470006945+0j)\n",
      "Epoka: 35, avg_loss: (1.3144176540869412+0j)\n",
      "Epoka: 36, avg_loss: (1.311353635046268+0j)\n",
      "Epoka: 37, avg_loss: (1.3083007229884593+0j)\n",
      "Epoka: 38, avg_loss: (1.3052589501793257+0j)\n",
      "Epoka: 39, avg_loss: (1.3022283480322432+0j)\n",
      "Epoka: 40, avg_loss: (1.299208947100113+0j)\n",
      "Epoka: 41, avg_loss: (1.2962007770677462+0j)\n",
      "Epoka: 42, avg_loss: (1.2932038667447023+0j)\n",
      "Epoka: 43, avg_loss: (1.2902182440585515+0j)\n",
      "Epoka: 44, avg_loss: (1.2872439360485826+0j)\n",
      "Epoka: 45, avg_loss: (1.2842809688599415+0j)\n",
      "Epoka: 46, avg_loss: (1.281329367738222+0j)\n",
      "Epoka: 47, avg_loss: (1.2783891570244836+0j)\n",
      "Epoka: 48, avg_loss: (1.2754603601507317+0j)\n",
      "Epoka: 49, avg_loss: (1.2725429996358035+0j)\n",
      "Epoka: 0, avg_loss: (1.18867869607531+0j)\n",
      "Epoka: 1, avg_loss: (1.186121538910945+0j)\n",
      "Epoka: 2, avg_loss: (1.183574938163357+0j)\n",
      "Epoka: 3, avg_loss: (1.1810388992623977+0j)\n",
      "Epoka: 4, avg_loss: (1.1785134270449757+0j)\n",
      "Epoka: 5, avg_loss: (1.1759985257534538+0j)\n",
      "Epoka: 6, avg_loss: (1.1734941990342265+0j)\n",
      "Epoka: 7, avg_loss: (1.1710004499365463+0j)\n",
      "Epoka: 8, avg_loss: (1.1685172809115456+0j)\n",
      "Epoka: 9, avg_loss: (1.1660446938114764+0j)\n",
      "Epoka: 10, avg_loss: (1.1635826898891652+0j)\n",
      "Epoka: 11, avg_loss: (1.1611312697976834+0j)\n",
      "Epoka: 12, avg_loss: (1.1586904335902288+0j)\n",
      "Epoka: 13, avg_loss: (1.1562601807202153+0j)\n",
      "Epoka: 14, avg_loss: (1.1538405100415836+0j)\n",
      "Epoka: 15, avg_loss: (1.15143141980932+0j)\n",
      "Epoka: 16, avg_loss: (1.1490329076801722+0j)\n",
      "Epoka: 17, avg_loss: (1.1466449707135933+0j)\n",
      "Epoka: 18, avg_loss: (1.1442676053728682+0j)\n",
      "Epoka: 19, avg_loss: (1.1419008075264667+0j)\n",
      "Epoka: 20, avg_loss: (1.1395445724495772+0j)\n",
      "Epoka: 21, avg_loss: (1.137198894825855+0j)\n",
      "Epoka: 22, avg_loss: (1.1348637687493568+0j)\n",
      "Epoka: 23, avg_loss: (1.1325391877266842+0j)\n",
      "Epoka: 24, avg_loss: (1.1302251446792957+0j)\n",
      "Epoka: 25, avg_loss: (1.1279216319460281+0j)\n",
      "Epoka: 26, avg_loss: (1.1256286412857999+0j)\n",
      "Epoka: 27, avg_loss: (1.1233461638804836+0j)\n",
      "Epoka: 28, avg_loss: (1.1210741903379728+0j)\n",
      "Epoka: 29, avg_loss: (1.1188127106954202+0j)\n",
      "Epoka: 30, avg_loss: (1.116561714422643+0j)\n",
      "Epoka: 31, avg_loss: (1.1143211904257067+0j)\n",
      "Epoka: 32, avg_loss: (1.1120911270506622+0j)\n",
      "Epoka: 33, avg_loss: (1.109871512087459+0j)\n",
      "Epoka: 34, avg_loss: (1.1076623327740018+0j)\n",
      "Epoka: 35, avg_loss: (1.1054635758003664+0j)\n",
      "Epoka: 36, avg_loss: (1.1032752273131663+0j)\n",
      "Epoka: 37, avg_loss: (1.1010972729200676+0j)\n",
      "Epoka: 38, avg_loss: (1.0989296976944403+0j)\n",
      "Epoka: 39, avg_loss: (1.096772486180141+0j)\n",
      "Epoka: 40, avg_loss: (1.0946256223964481+0j)\n",
      "Epoka: 41, avg_loss: (1.092489089843104+0j)\n",
      "Epoka: 42, avg_loss: (1.0903628715054932+0j)\n",
      "Epoka: 43, avg_loss: (1.0882469498599452+0j)\n",
      "Epoka: 44, avg_loss: (1.0861413068791375+0j)\n",
      "Epoka: 45, avg_loss: (1.084045924037626+0j)\n",
      "Epoka: 46, avg_loss: (1.081960782317473+0j)\n",
      "Epoka: 47, avg_loss: (1.0798858622139829+0j)\n",
      "Epoka: 48, avg_loss: (1.077821143741533+0j)\n",
      "Epoka: 49, avg_loss: (1.075766606439496+0j)\n",
      "Epoka: 0, avg_loss: (0.7614105223319442+0j)\n",
      "Epoka: 1, avg_loss: (0.7611459822098833+0j)\n",
      "Epoka: 2, avg_loss: (0.7608825665218149+0j)\n",
      "Epoka: 3, avg_loss: (0.7606202697072606+0j)\n",
      "Epoka: 4, avg_loss: (0.7603590862374281+0j)\n",
      "Epoka: 5, avg_loss: (0.7600990106150063+0j)\n",
      "Epoka: 6, avg_loss: (0.7598400373739708+0j)\n",
      "Epoka: 7, avg_loss: (0.7595821610793749+0j)\n",
      "Epoka: 8, avg_loss: (0.7593253763271608+0j)\n",
      "Epoka: 9, avg_loss: (0.7590696777439575+0j)\n",
      "Epoka: 10, avg_loss: (0.7588150599868865+0j)\n",
      "Epoka: 11, avg_loss: (0.7585615177433659+0j)\n",
      "Epoka: 12, avg_loss: (0.7583090457309222+0j)\n",
      "Epoka: 13, avg_loss: (0.7580576386969938+0j)\n",
      "Epoka: 14, avg_loss: (0.7578072914187439+0j)\n",
      "Epoka: 15, avg_loss: (0.7575579987028705+0j)\n",
      "Epoka: 16, avg_loss: (0.7573097553854181+0j)\n",
      "Epoka: 17, avg_loss: (0.7570625563315955+0j)\n",
      "Epoka: 18, avg_loss: (0.7568163964355828+0j)\n",
      "Epoka: 19, avg_loss: (0.7565712706203568+0j)\n",
      "Epoka: 20, avg_loss: (0.7563271738374995+0j)\n",
      "Epoka: 21, avg_loss: (0.7560841010670263+0j)\n",
      "Epoka: 22, avg_loss: (0.7558420473171975+0j)\n",
      "Epoka: 23, avg_loss: (0.7556010076243447+0j)\n",
      "Epoka: 24, avg_loss: (0.7553609770526903+0j)\n",
      "Epoka: 25, avg_loss: (0.7551219506941751+0j)\n",
      "Epoka: 26, avg_loss: (0.7548839236682766+0j)\n",
      "Epoka: 27, avg_loss: (0.7546468911218436+0j)\n",
      "Epoka: 28, avg_loss: (0.7544108482289144+0j)\n",
      "Epoka: 29, avg_loss: (0.7541757901905524+0j)\n",
      "Epoka: 30, avg_loss: (0.753941712234671+0j)\n",
      "Epoka: 31, avg_loss: (0.753708609615868+0j)\n",
      "Epoka: 32, avg_loss: (0.7534764776152538+0j)\n",
      "Epoka: 33, avg_loss: (0.7532453115402897+0j)\n",
      "Epoka: 34, avg_loss: (0.7530151067246151+0j)\n",
      "Epoka: 35, avg_loss: (0.7527858585278872+0j)\n",
      "Epoka: 36, avg_loss: (0.7525575623356182+0j)\n",
      "Epoka: 37, avg_loss: (0.7523302135590122+0j)\n",
      "Epoka: 38, avg_loss: (0.7521038076347996+0j)\n",
      "Epoka: 39, avg_loss: (0.7518783400250824+0j)\n",
      "Epoka: 40, avg_loss: (0.7516538062171744+0j)\n",
      "Epoka: 41, avg_loss: (0.7514302017234404+0j)\n",
      "Epoka: 42, avg_loss: (0.7512075220811394+0j)\n",
      "Epoka: 43, avg_loss: (0.7509857628522726+0j)\n",
      "Epoka: 44, avg_loss: (0.7507649196234234+0j)\n",
      "Epoka: 45, avg_loss: (0.7505449880056075+0j)\n",
      "Epoka: 46, avg_loss: (0.7503259636341183+0j)\n",
      "Epoka: 47, avg_loss: (0.7501078421683769+0j)\n",
      "Epoka: 48, avg_loss: (0.749890619291779+0j)\n",
      "Epoka: 49, avg_loss: (0.7496742907115446+0j)\n",
      "Epoka: 0, avg_loss: (0.6898330525126272+0j)\n",
      "Epoka: 1, avg_loss: (0.6898328432645022+0j)\n",
      "Epoka: 2, avg_loss: (0.6898326344381105+0j)\n",
      "Epoka: 3, avg_loss: (0.6898324260325835+0j)\n",
      "Epoka: 4, avg_loss: (0.689832218047051+0j)\n",
      "Epoka: 5, avg_loss: (0.6898320104806496+0j)\n",
      "Epoka: 6, avg_loss: (0.6898318033325133+0j)\n",
      "Epoka: 7, avg_loss: (0.6898315966017795+0j)\n",
      "Epoka: 8, avg_loss: (0.6898313902875877+0j)\n",
      "Epoka: 9, avg_loss: (0.6898311843890791+0j)\n",
      "Epoka: 10, avg_loss: (0.6898309789053966+0j)\n",
      "Epoka: 11, avg_loss: (0.6898307738356835+0j)\n",
      "Epoka: 12, avg_loss: (0.6898305691790878+0j)\n",
      "Epoka: 13, avg_loss: (0.6898303649347572+0j)\n",
      "Epoka: 14, avg_loss: (0.6898301611018419+0j)\n",
      "Epoka: 15, avg_loss: (0.6898299576794935+0j)\n",
      "Epoka: 16, avg_loss: (0.689829754666865+0j)\n",
      "Epoka: 17, avg_loss: (0.6898295520631125+0j)\n",
      "Epoka: 18, avg_loss: (0.6898293498673934+0j)\n",
      "Epoka: 19, avg_loss: (0.6898291480788661+0j)\n",
      "Epoka: 20, avg_loss: (0.6898289466966907+0j)\n",
      "Epoka: 21, avg_loss: (0.6898287457200301+0j)\n",
      "Epoka: 22, avg_loss: (0.6898285451480486+0j)\n",
      "Epoka: 23, avg_loss: (0.6898283449799115+0j)\n",
      "Epoka: 24, avg_loss: (0.6898281452147871+0j)\n",
      "Epoka: 25, avg_loss: (0.6898279458518448+0j)\n",
      "Epoka: 26, avg_loss: (0.6898277468902552+0j)\n",
      "Epoka: 27, avg_loss: (0.6898275483291912+0j)\n",
      "Epoka: 28, avg_loss: (0.6898273501678284+0j)\n",
      "Epoka: 29, avg_loss: (0.689827152405342+0j)\n",
      "Epoka: 30, avg_loss: (0.6898269550409103+0j)\n",
      "Epoka: 31, avg_loss: (0.6898267580737146+0j)\n",
      "Epoka: 32, avg_loss: (0.6898265615029334+0j)\n",
      "Epoka: 33, avg_loss: (0.6898263653277521+0j)\n",
      "Epoka: 34, avg_loss: (0.6898261695473544+0j)\n",
      "Epoka: 35, avg_loss: (0.6898259741609282+0j)\n",
      "Epoka: 36, avg_loss: (0.6898257791676615+0j)\n",
      "Epoka: 37, avg_loss: (0.6898255845667435+0j)\n",
      "Epoka: 38, avg_loss: (0.6898253903573665+0j)\n",
      "Epoka: 39, avg_loss: (0.6898251965387244+0j)\n",
      "Epoka: 40, avg_loss: (0.6898250031100114+0j)\n",
      "Epoka: 41, avg_loss: (0.6898248100704255+0j)\n",
      "Epoka: 42, avg_loss: (0.6898246174191639+0j)\n",
      "Epoka: 43, avg_loss: (0.6898244251554271+0j)\n",
      "Epoka: 44, avg_loss: (0.6898242332784174+0j)\n",
      "Epoka: 45, avg_loss: (0.6898240417873375+0j)\n",
      "Epoka: 46, avg_loss: (0.6898238506813935+0j)\n",
      "Epoka: 47, avg_loss: (0.6898236599597913+0j)\n",
      "Epoka: 48, avg_loss: (0.6898234696217409+0j)\n",
      "Epoka: 49, avg_loss: (0.6898232796664505+0j)\n",
      "Epoka: 0, avg_loss: (1.035160719413658+0j)\n",
      "Epoka: 1, avg_loss: (1.0334277648796957+0j)\n",
      "Epoka: 2, avg_loss: (1.0317034606939517+0j)\n",
      "Epoka: 3, avg_loss: (1.0299877756105615+0j)\n",
      "Epoka: 4, avg_loss: (1.0282806782628913+0j)\n",
      "Epoka: 5, avg_loss: (1.0265821371679016+0j)\n",
      "Epoka: 6, avg_loss: (1.0248921207304653+0j)\n",
      "Epoka: 7, avg_loss: (1.0232105972476535+0j)\n",
      "Epoka: 8, avg_loss: (1.0215375349129823+0j)\n",
      "Epoka: 9, avg_loss: (1.0198729018206052+0j)\n",
      "Epoka: 10, avg_loss: (1.0182166659694751+0j)\n",
      "Epoka: 11, avg_loss: (1.0165687952674602+0j)\n",
      "Epoka: 12, avg_loss: (1.0149292575354125+0j)\n",
      "Epoka: 13, avg_loss: (1.0132980205112039+0j)\n",
      "Epoka: 14, avg_loss: (1.0116750518537037+0j)\n",
      "Epoka: 15, avg_loss: (1.0100603191467252+0j)\n",
      "Epoka: 16, avg_loss: (1.0084537899029207+0j)\n",
      "Epoka: 17, avg_loss: (1.0068554315676366+0j)\n",
      "Epoka: 18, avg_loss: (1.005265211522715+0j)\n",
      "Epoka: 19, avg_loss: (1.0036830970902635+0j)\n",
      "Epoka: 20, avg_loss: (1.0021090555363674+0j)\n",
      "Epoka: 21, avg_loss: (1.0005430540747624+0j)\n",
      "Epoka: 22, avg_loss: (0.9989850598704632+0j)\n",
      "Epoka: 23, avg_loss: (0.9974350400433416+0j)\n",
      "Epoka: 24, avg_loss: (0.9958929616716607+0j)\n",
      "Epoka: 25, avg_loss: (0.9943587917955672+0j)\n",
      "Epoka: 26, avg_loss: (0.9928324974205288+0j)\n",
      "Epoka: 27, avg_loss: (0.9913140455207349+0j)\n",
      "Epoka: 28, avg_loss: (0.9898034030424461+0j)\n",
      "Epoka: 29, avg_loss: (0.9883005369072978+0j)\n",
      "Epoka: 30, avg_loss: (0.9868054140155565+0j)\n",
      "Epoka: 31, avg_loss: (0.9853180012493389+0j)\n",
      "Epoka: 32, avg_loss: (0.9838382654757714+0j)\n",
      "Epoka: 33, avg_loss: (0.9823661735501109+0j)\n",
      "Epoka: 34, avg_loss: (0.9809016923188237+0j)\n",
      "Epoka: 35, avg_loss: (0.9794447886226092+0j)\n",
      "Epoka: 36, avg_loss: (0.9779954292993868+0j)\n",
      "Epoka: 37, avg_loss: (0.9765535811872269+0j)\n",
      "Epoka: 38, avg_loss: (0.9751192111272491+0j)\n",
      "Epoka: 39, avg_loss: (0.9736922859664673+0j)\n",
      "Epoka: 40, avg_loss: (0.9722727725605878+0j)\n",
      "Epoka: 41, avg_loss: (0.9708606377767672+0j)\n",
      "Epoka: 42, avg_loss: (0.9694558484963253+0j)\n",
      "Epoka: 43, avg_loss: (0.9680583716174138+0j)\n",
      "Epoka: 44, avg_loss: (0.9666681740576304+0j)\n",
      "Epoka: 45, avg_loss: (0.965285222756609+0j)\n",
      "Epoka: 46, avg_loss: (0.9639094846785439+0j)\n",
      "Epoka: 47, avg_loss: (0.9625409268146876+0j)\n",
      "Epoka: 48, avg_loss: (0.9611795161857943+0j)\n",
      "Epoka: 49, avg_loss: (0.9598252198445258+0j)\n",
      "Epoka: 0, avg_loss: (0.7326751677081883+0j)\n",
      "Epoka: 1, avg_loss: (0.7325399997337713+0j)\n",
      "Epoka: 2, avg_loss: (0.7324053096237365+0j)\n",
      "Epoka: 3, avg_loss: (0.7322710954482862+0j)\n",
      "Epoka: 4, avg_loss: (0.7321373552865712+0j)\n",
      "Epoka: 5, avg_loss: (0.7320040872266512+0j)\n",
      "Epoka: 6, avg_loss: (0.7318712893654445+0j)\n",
      "Epoka: 7, avg_loss: (0.7317389598086815+0j)\n",
      "Epoka: 8, avg_loss: (0.7316070966708577+0j)\n",
      "Epoka: 9, avg_loss: (0.7314756980751882+0j)\n",
      "Epoka: 10, avg_loss: (0.7313447621535618+0j)\n",
      "Epoka: 11, avg_loss: (0.7312142870464938+0j)\n",
      "Epoka: 12, avg_loss: (0.7310842709030826+0j)\n",
      "Epoka: 13, avg_loss: (0.7309547118809647+0j)\n",
      "Epoka: 14, avg_loss: (0.7308256081462667+0j)\n",
      "Epoka: 15, avg_loss: (0.7306969578735654+0j)\n",
      "Epoka: 16, avg_loss: (0.7305687592458354+0j)\n",
      "Epoka: 17, avg_loss: (0.7304410104544179+0j)\n",
      "Epoka: 18, avg_loss: (0.7303137096989628+0j)\n",
      "Epoka: 19, avg_loss: (0.7301868551873943+0j)\n",
      "Epoka: 20, avg_loss: (0.730060445135866+0j)\n",
      "Epoka: 21, avg_loss: (0.7299344777687143+0j)\n",
      "Epoka: 22, avg_loss: (0.7298089513184172+0j)\n",
      "Epoka: 23, avg_loss: (0.7296838640255593+0j)\n",
      "Epoka: 24, avg_loss: (0.7295592141387728+0j)\n",
      "Epoka: 25, avg_loss: (0.7294349999147115+0j)\n",
      "Epoka: 26, avg_loss: (0.7293112196180027+0j)\n",
      "Epoka: 27, avg_loss: (0.7291878715212018+0j)\n",
      "Epoka: 28, avg_loss: (0.7290649539047589+0j)\n",
      "Epoka: 29, avg_loss: (0.7289424650569722+0j)\n",
      "Epoka: 30, avg_loss: (0.7288204032739458+0j)\n",
      "Epoka: 31, avg_loss: (0.7286987668595573+0j)\n",
      "Epoka: 32, avg_loss: (0.7285775541254067+0j)\n",
      "Epoka: 33, avg_loss: (0.7284567633907858+0j)\n",
      "Epoka: 34, avg_loss: (0.7283363929826299+0j)\n",
      "Epoka: 35, avg_loss: (0.7282164412354849+0j)\n",
      "Epoka: 36, avg_loss: (0.7280969064914653+0j)\n",
      "Epoka: 37, avg_loss: (0.7279777871002131+0j)\n",
      "Epoka: 38, avg_loss: (0.7278590814188617+0j)\n",
      "Epoka: 39, avg_loss: (0.7277407878119955+0j)\n",
      "Epoka: 40, avg_loss: (0.7276229046516128+0j)\n",
      "Epoka: 41, avg_loss: (0.7275054303170845+0j)\n",
      "Epoka: 42, avg_loss: (0.72738836319512+0j)\n",
      "Epoka: 43, avg_loss: (0.7272717016797272+0j)\n",
      "Epoka: 44, avg_loss: (0.7271554441721735+0j)\n",
      "Epoka: 45, avg_loss: (0.7270395890809522+0j)\n",
      "Epoka: 46, avg_loss: (0.7269241348217399+0j)\n",
      "Epoka: 47, avg_loss: (0.7268090798173649+0j)\n",
      "Epoka: 48, avg_loss: (0.7266944224977674+0j)\n",
      "Epoka: 49, avg_loss: (0.726580161299965+0j)\n",
      "Epoka: 0, avg_loss: (0.7113087876731422+0j)\n",
      "Epoka: 1, avg_loss: (0.7112427778152807+0j)\n",
      "Epoka: 2, avg_loss: (0.711176993506319+0j)\n",
      "Epoka: 3, avg_loss: (0.7111114338639776+0j)\n",
      "Epoka: 4, avg_loss: (0.7110460980099691+0j)\n",
      "Epoka: 5, avg_loss: (0.7109809850699798+0j)\n",
      "Epoka: 6, avg_loss: (0.7109160941736539+0j)\n",
      "Epoka: 7, avg_loss: (0.7108514244545616+0j)\n",
      "Epoka: 8, avg_loss: (0.7107869750501878+0j)\n",
      "Epoka: 9, avg_loss: (0.7107227451019096+0j)\n",
      "Epoka: 10, avg_loss: (0.7106587337549736+0j)\n",
      "Epoka: 11, avg_loss: (0.7105949401584787+0j)\n",
      "Epoka: 12, avg_loss: (0.7105313634653552+0j)\n",
      "Epoka: 13, avg_loss: (0.7104680028323431+0j)\n",
      "Epoka: 14, avg_loss: (0.7104048574199774+0j)\n",
      "Epoka: 15, avg_loss: (0.7103419263925584+0j)\n",
      "Epoka: 16, avg_loss: (0.7102792089181447+0j)\n",
      "Epoka: 17, avg_loss: (0.710216704168525+0j)\n",
      "Epoka: 18, avg_loss: (0.7101544113192025+0j)\n",
      "Epoka: 19, avg_loss: (0.7100923295493745+0j)\n",
      "Epoka: 20, avg_loss: (0.7100304580419122+0j)\n",
      "Epoka: 21, avg_loss: (0.7099687959833448+0j)\n",
      "Epoka: 22, avg_loss: (0.7099073425638377+0j)\n",
      "Epoka: 23, avg_loss: (0.7098460969771764+0j)\n",
      "Epoka: 24, avg_loss: (0.7097850584207434+0j)\n",
      "Epoka: 25, avg_loss: (0.7097242260955063+0j)\n",
      "Epoka: 26, avg_loss: (0.709663599205994+0j)\n",
      "Epoka: 27, avg_loss: (0.7096031769602791+0j)\n",
      "Epoka: 28, avg_loss: (0.7095429585699631+0j)\n",
      "Epoka: 29, avg_loss: (0.7094829432501534+0j)\n",
      "Epoka: 30, avg_loss: (0.7094231302194497+0j)\n",
      "Epoka: 31, avg_loss: (0.709363518699923+0j)\n",
      "Epoka: 32, avg_loss: (0.7093041079171007+0j)\n",
      "Epoka: 33, avg_loss: (0.7092448970999438+0j)\n",
      "Epoka: 34, avg_loss: (0.7091858854808369+0j)\n",
      "Epoka: 35, avg_loss: (0.7091270722955645+0j)\n",
      "Epoka: 36, avg_loss: (0.709068456783296+0j)\n",
      "Epoka: 37, avg_loss: (0.7090100381865672+0j)\n",
      "Epoka: 38, avg_loss: (0.7089518157512649+0j)\n",
      "Epoka: 39, avg_loss: (0.7088937887266099+0j)\n",
      "Epoka: 40, avg_loss: (0.7088359563651391+0j)\n",
      "Epoka: 41, avg_loss: (0.7087783179226848+0j)\n",
      "Epoka: 42, avg_loss: (0.7087208726583674+0j)\n",
      "Epoka: 43, avg_loss: (0.7086636198345692+0j)\n",
      "Epoka: 44, avg_loss: (0.7086065587169232+0j)\n",
      "Epoka: 45, avg_loss: (0.7085496885742945+0j)\n",
      "Epoka: 46, avg_loss: (0.7084930086787651+0j)\n",
      "Epoka: 47, avg_loss: (0.7084365183056164+0j)\n",
      "Epoka: 48, avg_loss: (0.708380216733314+0j)\n",
      "Epoka: 49, avg_loss: (0.7083241032434915+0j)\n",
      "Epoka: 0, avg_loss: (0.7765314996851733+0j)\n",
      "Epoka: 1, avg_loss: (0.7761488352528534+0j)\n",
      "Epoka: 2, avg_loss: (0.7757681445930555+0j)\n",
      "Epoka: 3, avg_loss: (0.7753894158729354+0j)\n",
      "Epoka: 4, avg_loss: (0.7750126373388567+0j)\n",
      "Epoka: 5, avg_loss: (0.7746377973158428+0j)\n",
      "Epoka: 6, avg_loss: (0.7742648842070269+0j)\n",
      "Epoka: 7, avg_loss: (0.7738938864931181+0j)\n",
      "Epoka: 8, avg_loss: (0.7735247927318566+0j)\n",
      "Epoka: 9, avg_loss: (0.7731575915574832+0j)\n",
      "Epoka: 10, avg_loss: (0.7727922716802047+0j)\n",
      "Epoka: 11, avg_loss: (0.7724288218856663+0j)\n",
      "Epoka: 12, avg_loss: (0.7720672310344278+0j)\n",
      "Epoka: 13, avg_loss: (0.7717074880614392+0j)\n",
      "Epoka: 14, avg_loss: (0.7713495819755224+0j)\n",
      "Epoka: 15, avg_loss: (0.7709935018588557+0j)\n",
      "Epoka: 16, avg_loss: (0.7706392368664654+0j)\n",
      "Epoka: 17, avg_loss: (0.7702867762257067+0j)\n",
      "Epoka: 18, avg_loss: (0.7699361092357709+0j)\n",
      "Epoka: 19, avg_loss: (0.7695872252671717+0j)\n",
      "Epoka: 20, avg_loss: (0.7692401137612517+0j)\n",
      "Epoka: 21, avg_loss: (0.7688947642296833+0j)\n",
      "Epoka: 22, avg_loss: (0.7685511662539749+0j)\n",
      "Epoka: 23, avg_loss: (0.7682093094849861+0j)\n",
      "Epoka: 24, avg_loss: (0.7678691836424352+0j)\n",
      "Epoka: 25, avg_loss: (0.7675307785144155+0j)\n",
      "Epoka: 26, avg_loss: (0.7671940839569183+0j)\n",
      "Epoka: 27, avg_loss: (0.766859089893355+0j)\n",
      "Epoka: 28, avg_loss: (0.7665257863140802+0j)\n",
      "Epoka: 29, avg_loss: (0.7661941632759217+0j)\n",
      "Epoka: 30, avg_loss: (0.7658642109017114+0j)\n",
      "Epoka: 31, avg_loss: (0.7655359193798229+0j)\n",
      "Epoka: 32, avg_loss: (0.7652092789637074+0j)\n",
      "Epoka: 33, avg_loss: (0.7648842799714337+0j)\n",
      "Epoka: 34, avg_loss: (0.7645609127852375+0j)\n",
      "Epoka: 35, avg_loss: (0.7642391678510616+0j)\n",
      "Epoka: 36, avg_loss: (0.7639190356781099+0j)\n",
      "Epoka: 37, avg_loss: (0.763600506838402+0j)\n",
      "Epoka: 38, avg_loss: (0.7632835719663252+0j)\n",
      "Epoka: 39, avg_loss: (0.7629682217581971+0j)\n",
      "Epoka: 40, avg_loss: (0.762654446971829+0j)\n",
      "Epoka: 41, avg_loss: (0.7623422384260842+0j)\n",
      "Epoka: 42, avg_loss: (0.7620315870004558+0j)\n",
      "Epoka: 43, avg_loss: (0.7617224836346284+0j)\n",
      "Epoka: 44, avg_loss: (0.7614149193280579+0j)\n",
      "Epoka: 45, avg_loss: (0.7611088851395473+0j)\n",
      "Epoka: 46, avg_loss: (0.7608043721868265+0j)\n",
      "Epoka: 47, avg_loss: (0.7605013716461327+0j)\n",
      "Epoka: 48, avg_loss: (0.7601998747517994+0j)\n",
      "Epoka: 49, avg_loss: (0.759899872795842+0j)\n",
      "Epoka: 0, avg_loss: (1.2653363919846534+0j)\n",
      "Epoka: 1, avg_loss: (1.2625640504586637+0j)\n",
      "Epoka: 2, avg_loss: (1.2598014791539929+0j)\n",
      "Epoka: 3, avg_loss: (1.2570486873619604+0j)\n",
      "Epoka: 4, avg_loss: (1.2543056839885638+0j)\n",
      "Epoka: 5, avg_loss: (1.2515724775532593+0j)\n",
      "Epoka: 6, avg_loss: (1.2488490761878124+0j)\n",
      "Epoka: 7, avg_loss: (1.246135487635207+0j)\n",
      "Epoka: 8, avg_loss: (1.2434317192486173+0j)\n",
      "Epoka: 9, avg_loss: (1.240737777990445+0j)\n",
      "Epoka: 10, avg_loss: (1.2380536704314171+0j)\n",
      "Epoka: 11, avg_loss: (1.2353794027497493+0j)\n",
      "Epoka: 12, avg_loss: (1.232714980730367+0j)\n",
      "Epoka: 13, avg_loss: (1.2300604097642058+0j)\n",
      "Epoka: 14, avg_loss: (1.2274156948475536+0j)\n",
      "Epoka: 15, avg_loss: (1.2247808405814826+0j)\n",
      "Epoka: 16, avg_loss: (1.222155851171321+0j)\n",
      "Epoka: 17, avg_loss: (1.2195407304262122+0j)\n",
      "Epoka: 18, avg_loss: (1.2169354817587283+0j)\n",
      "Epoka: 19, avg_loss: (1.2143401081845435+0j)\n",
      "Epoka: 20, avg_loss: (1.2117546123221907+0j)\n",
      "Epoka: 21, avg_loss: (1.209178996392868+0j)\n",
      "Epoka: 22, avg_loss: (1.2066132622203214+0j)\n",
      "Epoka: 23, avg_loss: (1.2040574112307862+0j)\n",
      "Epoka: 24, avg_loss: (1.2015114444530053+0j)\n",
      "Epoka: 25, avg_loss: (1.1989753625183073+0j)\n",
      "Epoka: 26, avg_loss: (1.1964491656607488+0j)\n",
      "Epoka: 27, avg_loss: (1.193932853717335+0j)\n",
      "Epoka: 28, avg_loss: (1.1914264261282945+0j)\n",
      "Epoka: 29, avg_loss: (1.1889298819374317+0j)\n",
      "Epoka: 30, avg_loss: (1.1864432197925419+0j)\n",
      "Epoka: 31, avg_loss: (1.1839664379458932+0j)\n",
      "Epoka: 32, avg_loss: (1.181499534254782+0j)\n",
      "Epoka: 33, avg_loss: (1.1790425061821441+0j)\n",
      "Epoka: 34, avg_loss: (1.1765953507972478+0j)\n",
      "Epoka: 35, avg_loss: (1.1741580647764405+0j)\n",
      "Epoka: 36, avg_loss: (1.1717306444039757+0j)\n",
      "Epoka: 37, avg_loss: (1.1693130855728955+0j)\n",
      "Epoka: 38, avg_loss: (1.1669053837859902+0j)\n",
      "Epoka: 39, avg_loss: (1.1645075341568172+0j)\n",
      "Epoka: 40, avg_loss: (1.1621195314107884+0j)\n",
      "Epoka: 41, avg_loss: (1.159741369886332+0j)\n",
      "Epoka: 42, avg_loss: (1.157373043536107+0j)\n",
      "Epoka: 43, avg_loss: (1.1550145459282948+0j)\n",
      "Epoka: 44, avg_loss: (1.1526658702479469+0j)\n",
      "Epoka: 45, avg_loss: (1.150327009298416+0j)\n",
      "Epoka: 46, avg_loss: (1.1479979555028266+0j)\n",
      "Epoka: 47, avg_loss: (1.145678700905633+0j)\n",
      "Epoka: 48, avg_loss: (1.1433692371742274+0j)\n",
      "Epoka: 49, avg_loss: (1.1410695556006183+0j)\n",
      "Epoka: 0, avg_loss: (0.8332892566356994+0j)\n",
      "Epoka: 1, avg_loss: (0.8326779654866501+0j)\n",
      "Epoka: 2, avg_loss: (0.8320697302359622+0j)\n",
      "Epoka: 3, avg_loss: (0.83146453325141+0j)\n",
      "Epoka: 4, avg_loss: (0.830862357011767+0j)\n",
      "Epoka: 5, avg_loss: (0.8302631841061311+0j)\n",
      "Epoka: 6, avg_loss: (0.8296669972332598+0j)\n",
      "Epoka: 7, avg_loss: (0.8290737792008991+0j)\n",
      "Epoka: 8, avg_loss: (0.8284835129251175+0j)\n",
      "Epoka: 9, avg_loss: (0.8278961814296435+0j)\n",
      "Epoka: 10, avg_loss: (0.82731176784521+0j)\n",
      "Epoka: 11, avg_loss: (0.8267302554088869+0j)\n",
      "Epoka: 12, avg_loss: (0.8261516274634382+0j)\n",
      "Epoka: 13, avg_loss: (0.8255758674566586+0j)\n",
      "Epoka: 14, avg_loss: (0.8250029589407302+0j)\n",
      "Epoka: 15, avg_loss: (0.8244328855715692+0j)\n",
      "Epoka: 16, avg_loss: (0.8238656311081908+0j)\n",
      "Epoka: 17, avg_loss: (0.8233011794120562+0j)\n",
      "Epoka: 18, avg_loss: (0.8227395144464417+0j)\n",
      "Epoka: 19, avg_loss: (0.8221806202757973+0j)\n",
      "Epoka: 20, avg_loss: (0.8216244810651151+0j)\n",
      "Epoka: 21, avg_loss: (0.8210710810792984+0j)\n",
      "Epoka: 22, avg_loss: (0.8205204046825331+0j)\n",
      "Epoka: 23, avg_loss: (0.8199724363376625+0j)\n",
      "Epoka: 24, avg_loss: (0.8194271606055665+0j)\n",
      "Epoka: 25, avg_loss: (0.8188845621445372+0j)\n",
      "Epoka: 26, avg_loss: (0.8183446257096668+0j)\n",
      "Epoka: 27, avg_loss: (0.8178073361522351+0j)\n",
      "Epoka: 28, avg_loss: (0.8172726784190926+0j)\n",
      "Epoka: 29, avg_loss: (0.8167406375520601+0j)\n",
      "Epoka: 30, avg_loss: (0.8162111986873143+0j)\n",
      "Epoka: 31, avg_loss: (0.8156843470547963+0j)\n",
      "Epoka: 32, avg_loss: (0.815160067977606+0j)\n",
      "Epoka: 33, avg_loss: (0.814638346871406+0j)\n",
      "Epoka: 34, avg_loss: (0.8141191692438312+0j)\n",
      "Epoka: 35, avg_loss: (0.813602520693896+0j)\n",
      "Epoka: 36, avg_loss: (0.8130883869114122+0j)\n",
      "Epoka: 37, avg_loss: (0.8125767536763995+0j)\n",
      "Epoka: 38, avg_loss: (0.8120676068585034+0j)\n",
      "Epoka: 39, avg_loss: (0.8115609324164258+0j)\n",
      "Epoka: 40, avg_loss: (0.8110567163973397+0j)\n",
      "Epoka: 41, avg_loss: (0.8105549449363242+0j)\n",
      "Epoka: 42, avg_loss: (0.8100556042557918+0j)\n",
      "Epoka: 43, avg_loss: (0.8095586806649254+0j)\n",
      "Epoka: 44, avg_loss: (0.8090641605591136+0j)\n",
      "Epoka: 45, avg_loss: (0.8085720304193897+0j)\n",
      "Epoka: 46, avg_loss: (0.8080822768118779+0j)\n",
      "Epoka: 47, avg_loss: (0.8075948863872383+0j)\n",
      "Epoka: 48, avg_loss: (0.8071098458801146+0j)\n",
      "Epoka: 49, avg_loss: (0.8066271421085904+0j)\n",
      "Epoka: 0, avg_loss: (1.1846697635574424+0j)\n",
      "Epoka: 1, avg_loss: (1.1822079516876143+0j)\n",
      "Epoka: 2, avg_loss: (1.1797559559983215+0j)\n",
      "Epoka: 3, avg_loss: (1.1773137727702983+0j)\n",
      "Epoka: 4, avg_loss: (1.1748813979028598+0j)\n",
      "Epoka: 5, avg_loss: (1.172458826915035+0j)\n",
      "Epoka: 6, avg_loss: (1.1700460549467266+0j)\n",
      "Epoka: 7, avg_loss: (1.1676430767599604+0j)\n",
      "Epoka: 8, avg_loss: (1.1652498867401884+0j)\n",
      "Epoka: 9, avg_loss: (1.1628664788976557+0j)\n",
      "Epoka: 10, avg_loss: (1.160492846868834+0j)\n",
      "Epoka: 11, avg_loss: (1.1581289839179059+0j)\n",
      "Epoka: 12, avg_loss: (1.155774882938327+0j)\n",
      "Epoka: 13, avg_loss: (1.1534305364544284+0j)\n",
      "Epoka: 14, avg_loss: (1.151095936623106+0j)\n",
      "Epoka: 15, avg_loss: (1.14877107523553+0j)\n",
      "Epoka: 16, avg_loss: (1.1464559437189656+0j)\n",
      "Epoka: 17, avg_loss: (1.1441505331385937+0j)\n",
      "Epoka: 18, avg_loss: (1.1418548341994366+0j)\n",
      "Epoka: 19, avg_loss: (1.1395688372483121+0j)\n",
      "Epoka: 20, avg_loss: (1.1372925322758527+0j)\n",
      "Epoka: 21, avg_loss: (1.1350259089185848+0j)\n",
      "Epoka: 22, avg_loss: (1.1327689564610501+0j)\n",
      "Epoka: 23, avg_loss: (1.1305216638379836+0j)\n",
      "Epoka: 24, avg_loss: (1.1282840196365551+0j)\n",
      "Epoka: 25, avg_loss: (1.1260560120986502+0j)\n",
      "Epoka: 26, avg_loss: (1.1238376291232028+0j)\n",
      "Epoka: 27, avg_loss: (1.1216288582685814+0j)\n",
      "Epoka: 28, avg_loss: (1.1194296867550253+0j)\n",
      "Epoka: 29, avg_loss: (1.117240101467126+0j)\n",
      "Epoka: 30, avg_loss: (1.115060088956353+0j)\n",
      "Epoka: 31, avg_loss: (1.1128896354436306+0j)\n",
      "Epoka: 32, avg_loss: (1.1107287268219581+0j)\n",
      "Epoka: 33, avg_loss: (1.1085773486590762+0j)\n",
      "Epoka: 34, avg_loss: (1.1064354862001693+0j)\n",
      "Epoka: 35, avg_loss: (1.1043031243706134+0j)\n",
      "Epoka: 36, avg_loss: (1.102180247778777+0j)\n",
      "Epoka: 37, avg_loss: (1.1000668407188412+0j)\n",
      "Epoka: 38, avg_loss: (1.0979628871736724+0j)\n",
      "Epoka: 39, avg_loss: (1.0958683708177297+0j)\n",
      "Epoka: 40, avg_loss: (1.0937832750200136+0j)\n",
      "Epoka: 41, avg_loss: (1.0917075828470346+0j)\n",
      "Epoka: 42, avg_loss: (1.0896412770658466+0j)\n",
      "Epoka: 43, avg_loss: (1.0875843401470748+0j)\n",
      "Epoka: 44, avg_loss: (1.0855367542680185+0j)\n",
      "Epoka: 45, avg_loss: (1.0834985013157448+0j)\n",
      "Epoka: 46, avg_loss: (1.0814695628902464+0j)\n",
      "Epoka: 47, avg_loss: (1.079449920307608+0j)\n",
      "Epoka: 48, avg_loss: (1.0774395546032125+0j)\n",
      "Epoka: 49, avg_loss: (1.0754384465349642+0j)\n",
      "Epoka: 0, avg_loss: (0.7543428440519888+0j)\n",
      "Epoka: 1, avg_loss: (0.7541553671014066+0j)\n",
      "Epoka: 2, avg_loss: (0.753968509704036+0j)\n",
      "Epoka: 3, avg_loss: (0.7537822695010409+0j)\n",
      "Epoka: 4, avg_loss: (0.7535966441438923+0j)\n",
      "Epoka: 5, avg_loss: (0.7534116312943192+0j)\n",
      "Epoka: 6, avg_loss: (0.7532272286242548+0j)\n",
      "Epoka: 7, avg_loss: (0.7530434338157891+0j)\n",
      "Epoka: 8, avg_loss: (0.7528602445611178+0j)\n",
      "Epoka: 9, avg_loss: (0.7526776585624904+0j)\n",
      "Epoka: 10, avg_loss: (0.7524956735321663+0j)\n",
      "Epoka: 11, avg_loss: (0.7523142871923609+0j)\n",
      "Epoka: 12, avg_loss: (0.7521334972751963+0j)\n",
      "Epoka: 13, avg_loss: (0.7519533015226553+0j)\n",
      "Epoka: 14, avg_loss: (0.7517736976865309+0j)\n",
      "Epoka: 15, avg_loss: (0.7515946835283802+0j)\n",
      "Epoka: 16, avg_loss: (0.7514162568194738+0j)\n",
      "Epoka: 17, avg_loss: (0.7512384153407515+0j)\n",
      "Epoka: 18, avg_loss: (0.7510611568827712+0j)\n",
      "Epoka: 19, avg_loss: (0.7508844792456635+0j)\n",
      "Epoka: 20, avg_loss: (0.7507083802390859+0j)\n",
      "Epoka: 21, avg_loss: (0.7505328576821749+0j)\n",
      "Epoka: 22, avg_loss: (0.7503579094034993+0j)\n",
      "Epoka: 23, avg_loss: (0.750183533241015+0j)\n",
      "Epoka: 24, avg_loss: (0.750009727042019+0j)\n",
      "Epoka: 25, avg_loss: (0.7498364886631028+0j)\n",
      "Epoka: 26, avg_loss: (0.7496638159701081+0j)\n",
      "Epoka: 27, avg_loss: (0.7494917068380814+0j)\n",
      "Epoka: 28, avg_loss: (0.7493201591512283+0j)\n",
      "Epoka: 29, avg_loss: (0.7491491708028712+0j)\n",
      "Epoka: 30, avg_loss: (0.7489787396954012+0j)\n",
      "Epoka: 31, avg_loss: (0.748808863740237+0j)\n",
      "Epoka: 32, avg_loss: (0.7486395408577797+0j)\n",
      "Epoka: 33, avg_loss: (0.7484707689773699+0j)\n",
      "Epoka: 34, avg_loss: (0.7483025460372419+0j)\n",
      "Epoka: 35, avg_loss: (0.7481348699844852+0j)\n",
      "Epoka: 36, avg_loss: (0.7479677387749969+0j)\n",
      "Epoka: 37, avg_loss: (0.7478011503734389+0j)\n",
      "Epoka: 38, avg_loss: (0.7476351027531996+0j)\n",
      "Epoka: 39, avg_loss: (0.7474695938963479+0j)\n",
      "Epoka: 40, avg_loss: (0.747304621793594+0j)\n",
      "Epoka: 41, avg_loss: (0.7471401844442426+0j)\n",
      "Epoka: 42, avg_loss: (0.7469762798561558+0j)\n",
      "Epoka: 43, avg_loss: (0.7468129060457123+0j)\n",
      "Epoka: 44, avg_loss: (0.7466500610377634+0j)\n",
      "Epoka: 45, avg_loss: (0.7464877428655904+0j)\n",
      "Epoka: 46, avg_loss: (0.7463259495708714+0j)\n",
      "Epoka: 47, avg_loss: (0.7461646792036304+0j)\n",
      "Epoka: 48, avg_loss: (0.7460039298222056+0j)\n",
      "Epoka: 49, avg_loss: (0.7458436994932048+0j)\n",
      "Epoka: 0, avg_loss: (0.8480666704569214+0j)\n",
      "Epoka: 1, avg_loss: (0.8474133088666577+0j)\n",
      "Epoka: 2, avg_loss: (0.8467630221522059+0j)\n",
      "Epoka: 3, avg_loss: (0.8461157941606943+0j)\n",
      "Epoka: 4, avg_loss: (0.8454716088277399+0j)\n",
      "Epoka: 5, avg_loss: (0.8448304501770284+0j)\n",
      "Epoka: 6, avg_loss: (0.8441923023199003+0j)\n",
      "Epoka: 7, avg_loss: (0.8435571494549338+0j)\n",
      "Epoka: 8, avg_loss: (0.8429249758675246+0j)\n",
      "Epoka: 9, avg_loss: (0.8422957659294775+0j)\n",
      "Epoka: 10, avg_loss: (0.8416695040985832+0j)\n",
      "Epoka: 11, avg_loss: (0.841046174918207+0j)\n",
      "Epoka: 12, avg_loss: (0.8404257630168698+0j)\n",
      "Epoka: 13, avg_loss: (0.8398082531078356+0j)\n",
      "Epoka: 14, avg_loss: (0.8391936299886967+0j)\n",
      "Epoka: 15, avg_loss: (0.83858187854096+0j)\n",
      "Epoka: 16, avg_loss: (0.8379729837296322+0j)\n",
      "Epoka: 17, avg_loss: (0.837366930602803+0j)\n",
      "Epoka: 18, avg_loss: (0.8367637042912444+0j)\n",
      "Epoka: 19, avg_loss: (0.8361632900079832+0j)\n",
      "Epoka: 20, avg_loss: (0.8355656730479026+0j)\n",
      "Epoka: 21, avg_loss: (0.8349708387873247+0j)\n",
      "Epoka: 22, avg_loss: (0.8343787726835996+0j)\n",
      "Epoka: 23, avg_loss: (0.833789460274701+0j)\n",
      "Epoka: 24, avg_loss: (0.8332028871788141+0j)\n",
      "Epoka: 25, avg_loss: (0.8326190390939308+0j)\n",
      "Epoka: 26, avg_loss: (0.8320379017974372+0j)\n",
      "Epoka: 27, avg_loss: (0.8314594611457146+0j)\n",
      "Epoka: 28, avg_loss: (0.8308837030737274+0j)\n",
      "Epoka: 29, avg_loss: (0.8303106135946252+0j)\n",
      "Epoka: 30, avg_loss: (0.8297401787993339+0j)\n",
      "Epoka: 31, avg_loss: (0.8291723848561556+0j)\n",
      "Epoka: 32, avg_loss: (0.8286072180103672+0j)\n",
      "Epoka: 33, avg_loss: (0.8280446645838199+0j)\n",
      "Epoka: 34, avg_loss: (0.8274847109745391+0j)\n",
      "Epoka: 35, avg_loss: (0.8269273436563243+0j)\n",
      "Epoka: 36, avg_loss: (0.826372549178355+0j)\n",
      "Epoka: 37, avg_loss: (0.8258203141647912+0j)\n",
      "Epoka: 38, avg_loss: (0.8252706253143821+0j)\n",
      "Epoka: 39, avg_loss: (0.8247234694000657+0j)\n",
      "Epoka: 40, avg_loss: (0.8241788332685814+0j)\n",
      "Epoka: 41, avg_loss: (0.8236367038400753+0j)\n",
      "Epoka: 42, avg_loss: (0.8230970681077088+0j)\n",
      "Epoka: 43, avg_loss: (0.822559913137274+0j)\n",
      "Epoka: 44, avg_loss: (0.8220252260667996+0j)\n",
      "Epoka: 45, avg_loss: (0.8214929941061628+0j)\n",
      "Epoka: 46, avg_loss: (0.8209632045367118+0j)\n",
      "Epoka: 47, avg_loss: (0.8204358447108737+0j)\n",
      "Epoka: 48, avg_loss: (0.8199109020517721+0j)\n",
      "Epoka: 49, avg_loss: (0.8193883640528493+0j)\n",
      "Epoka: 0, avg_loss: (1.3306325589399048+0j)\n",
      "Epoka: 1, avg_loss: (1.3276215010370929+0j)\n",
      "Epoka: 2, avg_loss: (1.3246200760325149+0j)\n",
      "Epoka: 3, avg_loss: (1.3216283047827797+0j)\n",
      "Epoka: 4, avg_loss: (1.3186462077803822+0j)\n",
      "Epoka: 5, avg_loss: (1.3156738051497707+0j)\n",
      "Epoka: 6, avg_loss: (1.3127111166434817+0j)\n",
      "Epoka: 7, avg_loss: (1.3097581616382974+0j)\n",
      "Epoka: 8, avg_loss: (1.3068149591314655+0j)\n",
      "Epoka: 9, avg_loss: (1.3038815277369655+0j)\n",
      "Epoka: 10, avg_loss: (1.3009578856818262+0j)\n",
      "Epoka: 11, avg_loss: (1.2980440508024855+0j)\n",
      "Epoka: 12, avg_loss: (1.2951400405412319+0j)\n",
      "Epoka: 13, avg_loss: (1.2922458719426797+0j)\n",
      "Epoka: 14, avg_loss: (1.2893615616503102+0j)\n",
      "Epoka: 15, avg_loss: (1.2864871259030901+0j)\n",
      "Epoka: 16, avg_loss: (1.283622580532123+0j)\n",
      "Epoka: 17, avg_loss: (1.2807679409574042+0j)\n",
      "Epoka: 18, avg_loss: (1.2779232221846075+0j)\n",
      "Epoka: 19, avg_loss: (1.275088438801976+0j)\n",
      "Epoka: 20, avg_loss: (1.272263604977261+0j)\n",
      "Epoka: 21, avg_loss: (1.2694487344547394+0j)\n",
      "Epoka: 22, avg_loss: (1.2666438405523255+0j)\n",
      "Epoka: 23, avg_loss: (1.26384893615873+0j)\n",
      "Epoka: 24, avg_loss: (1.2610640337307322+0j)\n",
      "Epoka: 25, avg_loss: (1.2582891452905178+0j)\n",
      "Epoka: 26, avg_loss: (1.2555242824230888+0j)\n",
      "Epoka: 27, avg_loss: (1.2527694562737974+0j)\n",
      "Epoka: 28, avg_loss: (1.2500246775459247+0j)\n",
      "Epoka: 29, avg_loss: (1.2472899564983888+0j)\n",
      "Epoka: 30, avg_loss: (1.2445653029435066+0j)\n",
      "Epoka: 31, avg_loss: (1.2418507262448852+0j)\n",
      "Epoka: 32, avg_loss: (1.2391462353153855+0j)\n",
      "Epoka: 33, avg_loss: (1.2364518386151881+0j)\n",
      "Epoka: 34, avg_loss: (1.2337675441499636+0j)\n",
      "Epoka: 35, avg_loss: (1.23109335946914+0j)\n",
      "Epoka: 36, avg_loss: (1.228429291664264+0j)\n",
      "Epoka: 37, avg_loss: (1.2257753473674782+0j)\n",
      "Epoka: 38, avg_loss: (1.2231315327501016+0j)\n",
      "Epoka: 39, avg_loss: (1.2204978535212934+0j)\n",
      "Epoka: 40, avg_loss: (1.2178743149268598+0j)\n",
      "Epoka: 41, avg_loss: (1.2152609217481403+0j)\n",
      "Epoka: 42, avg_loss: (1.2126576783010112+0j)\n",
      "Epoka: 43, avg_loss: (1.2100645884350054+0j)\n",
      "Epoka: 44, avg_loss: (1.207481655532536+0j)\n",
      "Epoka: 45, avg_loss: (1.2049088825082312+0j)\n",
      "Epoka: 46, avg_loss: (1.2023462718083857+0j)\n",
      "Epoka: 47, avg_loss: (1.1997938254105207+0j)\n",
      "Epoka: 48, avg_loss: (1.197251544823063+0j)\n",
      "Epoka: 49, avg_loss: (1.1947194310851261+0j)\n",
      "Epoka: 0, avg_loss: (0.993225877854815+0j)\n",
      "Epoka: 1, avg_loss: (0.9916481133422105+0j)\n",
      "Epoka: 2, avg_loss: (0.9900786521888713+0j)\n",
      "Epoka: 3, avg_loss: (0.9885174611419478+0j)\n",
      "Epoka: 4, avg_loss: (0.9869645068602942+0j)\n",
      "Epoka: 5, avg_loss: (0.9854197559187517+0j)\n",
      "Epoka: 6, avg_loss: (0.9838831748124006+0j)\n",
      "Epoka: 7, avg_loss: (0.9823547299607481+0j)\n",
      "Epoka: 8, avg_loss: (0.9808343877118963+0j)\n",
      "Epoka: 9, avg_loss: (0.9793221143466372+0j)\n",
      "Epoka: 10, avg_loss: (0.9778178760825239+0j)\n",
      "Epoka: 11, avg_loss: (0.9763216390778829+0j)\n",
      "Epoka: 12, avg_loss: (0.9748333694357819+0j)\n",
      "Epoka: 13, avg_loss: (0.9733530332079536+0j)\n",
      "Epoka: 14, avg_loss: (0.9718805963986707+0j)\n",
      "Epoka: 15, avg_loss: (0.9704160249685666+0j)\n",
      "Epoka: 16, avg_loss: (0.9689592848384252+0j)\n",
      "Epoka: 17, avg_loss: (0.9675103418928993+0j)\n",
      "Epoka: 18, avg_loss: (0.966069161984199+0j)\n",
      "Epoka: 19, avg_loss: (0.9646357109357259+0j)\n",
      "Epoka: 20, avg_loss: (0.9632099545456554+0j)\n",
      "Epoka: 21, avg_loss: (0.9617918585904753+0j)\n",
      "Epoka: 22, avg_loss: (0.960381388828472+0j)\n",
      "Epoka: 23, avg_loss: (0.9589785110031697+0j)\n",
      "Epoka: 24, avg_loss: (0.9575831908467228+0j)\n",
      "Epoka: 25, avg_loss: (0.9561953940832484+0j)\n",
      "Epoka: 26, avg_loss: (0.954815086432129+0j)\n",
      "Epoka: 27, avg_loss: (0.9534422336112512+0j)\n",
      "Epoka: 28, avg_loss: (0.9520768013401953+0j)\n",
      "Epoka: 29, avg_loss: (0.9507187553433863+0j)\n",
      "Epoka: 30, avg_loss: (0.9493680613531899+0j)\n",
      "Epoka: 31, avg_loss: (0.9480246851129581+0j)\n",
      "Epoka: 32, avg_loss: (0.9466885923800292+0j)\n",
      "Epoka: 33, avg_loss: (0.9453597489286802+0j)\n",
      "Epoka: 34, avg_loss: (0.9440381205530285+0j)\n",
      "Epoka: 35, avg_loss: (0.942723673069884+0j)\n",
      "Epoka: 36, avg_loss: (0.9414163723215611+0j)\n",
      "Epoka: 37, avg_loss: (0.9401161841786335+0j)\n",
      "Epoka: 38, avg_loss: (0.9388230745426459+0j)\n",
      "Epoka: 39, avg_loss: (0.9375370093487791+0j)\n",
      "Epoka: 40, avg_loss: (0.9362579545684659+0j)\n",
      "Epoka: 41, avg_loss: (0.9349858762119633+0j)\n",
      "Epoka: 42, avg_loss: (0.9337207403308678+0j)\n",
      "Epoka: 43, avg_loss: (0.9324625130206062+0j)\n",
      "Epoka: 44, avg_loss: (0.931211160422855+0j)\n",
      "Epoka: 45, avg_loss: (0.9299666487279272+0j)\n",
      "Epoka: 46, avg_loss: (0.9287289441771175+0j)\n",
      "Epoka: 47, avg_loss: (0.9274980130649922+0j)\n",
      "Epoka: 48, avg_loss: (0.9262738217416364+0j)\n",
      "Epoka: 49, avg_loss: (0.9250563366148663+0j)\n",
      "Epoka: 0, avg_loss: (1.1585018414892192+0j)\n",
      "Epoka: 1, avg_loss: (1.156142088958683+0j)\n",
      "Epoka: 2, avg_loss: (1.153792035533587+0j)\n",
      "Epoka: 3, avg_loss: (1.1514516746617707+0j)\n",
      "Epoka: 4, avg_loss: (1.1491209994310936+0j)\n",
      "Epoka: 5, avg_loss: (1.146800002570598+0j)\n",
      "Epoka: 6, avg_loss: (1.1444886764517401+0j)\n",
      "Epoka: 7, avg_loss: (1.142187013089692+0j)\n",
      "Epoka: 8, avg_loss: (1.1398950041446971+0j)\n",
      "Epoka: 9, avg_loss: (1.1376126409234957+0j)\n",
      "Epoka: 10, avg_loss: (1.1353399143808165+0j)\n",
      "Epoka: 11, avg_loss: (1.133076815120927+0j)\n",
      "Epoka: 12, avg_loss: (1.1308233333992481+0j)\n",
      "Epoka: 13, avg_loss: (1.1285794591240328+0j)\n",
      "Epoka: 14, avg_loss: (1.1263451818581056+0j)\n",
      "Epoka: 15, avg_loss: (1.1241204908206581+0j)\n",
      "Epoka: 16, avg_loss: (1.121905374889112+0j)\n",
      "Epoka: 17, avg_loss: (1.119699822601036+0j)\n",
      "Epoka: 18, avg_loss: (1.1175038221561235+0j)\n",
      "Epoka: 19, avg_loss: (1.1153173614182257+0j)\n",
      "Epoka: 20, avg_loss: (1.1131404279174493+0j)\n",
      "Epoka: 21, avg_loss: (1.1109730088522927+0j)\n",
      "Epoka: 22, avg_loss: (1.1088150910918595+0j)\n",
      "Epoka: 23, avg_loss: (1.1066666611781057+0j)\n",
      "Epoka: 24, avg_loss: (1.1045277053281612+0j)\n",
      "Epoka: 25, avg_loss: (1.1023982094366829+0j)\n",
      "Epoka: 26, avg_loss: (1.1002781590782649+0j)\n",
      "Epoka: 27, avg_loss: (1.0981675395099142+0j)\n",
      "Epoka: 28, avg_loss: (1.0960663356735523+0j)\n",
      "Epoka: 29, avg_loss: (1.0939745321985848+0j)\n",
      "Epoka: 30, avg_loss: (1.0918921134044957+0j)\n",
      "Epoka: 31, avg_loss: (1.0898190633035205+0j)\n",
      "Epoka: 32, avg_loss: (1.087755365603328+0j)\n",
      "Epoka: 33, avg_loss: (1.085701003709772+0j)\n",
      "Epoka: 34, avg_loss: (1.083655960729673+0j)\n",
      "Epoka: 35, avg_loss: (1.081620219473646+0j)\n",
      "Epoka: 36, avg_loss: (1.07959376245897+0j)\n",
      "Epoka: 37, avg_loss: (1.0775765719124863+0j)\n",
      "Epoka: 38, avg_loss: (1.0755686297735536+0j)\n",
      "Epoka: 39, avg_loss: (1.0735699176970221+0j)\n",
      "Epoka: 40, avg_loss: (1.07158041705625+0j)\n",
      "Epoka: 41, avg_loss: (1.0696001089461584+0j)\n",
      "Epoka: 42, avg_loss: (1.0676289741863156+0j)\n",
      "Epoka: 43, avg_loss: (1.0656669933240501+0j)\n",
      "Epoka: 44, avg_loss: (1.0637141466376+0j)\n",
      "Epoka: 45, avg_loss: (1.0617704141392914+0j)\n",
      "Epoka: 46, avg_loss: (1.059835775578743+0j)\n",
      "Epoka: 47, avg_loss: (1.0579102104461002+0j)\n",
      "Epoka: 48, avg_loss: (1.0559936979752893+0j)\n",
      "Epoka: 49, avg_loss: (1.0540862171473089+0j)\n",
      "Epoka: 0, avg_loss: (0.8594560563559195+0j)\n",
      "Epoka: 1, avg_loss: (0.85857337199863+0j)\n",
      "Epoka: 2, avg_loss: (0.8576956148717406+0j)\n",
      "Epoka: 3, avg_loss: (0.8568227581845733+0j)\n",
      "Epoka: 4, avg_loss: (0.8559547752469867+0j)\n",
      "Epoka: 5, avg_loss: (0.8550916394699171+0j)\n",
      "Epoka: 6, avg_loss: (0.8542333243659022+0j)\n",
      "Epoka: 7, avg_loss: (0.8533798035495898+0j)\n",
      "Epoka: 8, avg_loss: (0.8525310507382197+0j)\n",
      "Epoka: 9, avg_loss: (0.8516870397520965+0j)\n",
      "Epoka: 10, avg_loss: (0.8508477445150316+0j)\n",
      "Epoka: 11, avg_loss: (0.8500131390547762+0j)\n",
      "Epoka: 12, avg_loss: (0.8491831975034315+0j)\n",
      "Epoka: 13, avg_loss: (0.8483578940978457+0j)\n",
      "Epoka: 14, avg_loss: (0.8475372031799857+0j)\n",
      "Epoka: 15, avg_loss: (0.8467210991972959+0j)\n",
      "Epoka: 16, avg_loss: (0.8459095567030422+0j)\n",
      "Epoka: 17, avg_loss: (0.8451025503566341+0j)\n",
      "Epoka: 18, avg_loss: (0.8443000549239326+0j)\n",
      "Epoka: 19, avg_loss: (0.8435020452775405+0j)\n",
      "Epoka: 20, avg_loss: (0.842708496397077+0j)\n",
      "Epoka: 21, avg_loss: (0.8419193833694407+0j)\n",
      "Epoka: 22, avg_loss: (0.8411346813890477+0j)\n",
      "Epoka: 23, avg_loss: (0.8403543657580602+0j)\n",
      "Epoka: 24, avg_loss: (0.839578411886599+0j)\n",
      "Epoka: 25, avg_loss: (0.8388067952929463+0j)\n",
      "Epoka: 26, avg_loss: (0.8380394916037195+0j)\n",
      "Epoka: 27, avg_loss: (0.8372764765540441+0j)\n",
      "Epoka: 28, avg_loss: (0.8365177259877096+0j)\n",
      "Epoka: 29, avg_loss: (0.8357632158573047+0j)\n",
      "Epoka: 30, avg_loss: (0.8350129222243482+0j)\n",
      "Epoka: 31, avg_loss: (0.8342668212593969+0j)\n",
      "Epoka: 32, avg_loss: (0.8335248892421471+0j)\n",
      "Epoka: 33, avg_loss: (0.8327871025615234+0j)\n",
      "Epoka: 34, avg_loss: (0.8320534377157455+0j)\n",
      "Epoka: 35, avg_loss: (0.8313238713123932+0j)\n",
      "Epoka: 36, avg_loss: (0.8305983800684561+0j)\n",
      "Epoka: 37, avg_loss: (0.829876940810365+0j)\n",
      "Epoka: 38, avg_loss: (0.8291595304740184+0j)\n",
      "Epoka: 39, avg_loss: (0.8284461261047936+0j)\n",
      "Epoka: 40, avg_loss: (0.82773670485755+0j)\n",
      "Epoka: 41, avg_loss: (0.8270312439966143+0j)\n",
      "Epoka: 42, avg_loss: (0.8263297208957618+0j)\n",
      "Epoka: 43, avg_loss: (0.8256321130381815+0j)\n",
      "Epoka: 44, avg_loss: (0.824938398016435+0j)\n",
      "Epoka: 45, avg_loss: (0.8242485535324005+0j)\n",
      "Epoka: 46, avg_loss: (0.823562557397209+0j)\n",
      "Epoka: 47, avg_loss: (0.8228803875311699+0j)\n",
      "Epoka: 48, avg_loss: (0.8222020219636881+0j)\n",
      "Epoka: 49, avg_loss: (0.8215274388331675+0j)\n",
      "Epoka: 0, avg_loss: (1.3717058732906482+0j)\n",
      "Epoka: 1, avg_loss: (1.3685437220114767+0j)\n",
      "Epoka: 2, avg_loss: (1.3653907583752976+0j)\n",
      "Epoka: 3, avg_loss: (1.3622470098431343+0j)\n",
      "Epoka: 4, avg_loss: (1.3591125036743141+0j)\n",
      "Epoka: 5, avg_loss: (1.3559872669227113+0j)\n",
      "Epoka: 6, avg_loss: (1.3528713264328884+0j)\n",
      "Epoka: 7, avg_loss: (1.3497647088361038+0j)\n",
      "Epoka: 8, avg_loss: (1.3466674405462227+0j)\n",
      "Epoka: 9, avg_loss: (1.343579547755486+0j)\n",
      "Epoka: 10, avg_loss: (1.3405010564301734+0j)\n",
      "Epoka: 11, avg_loss: (1.3374319923061295+0j)\n",
      "Epoka: 12, avg_loss: (1.3343723808841923+0j)\n",
      "Epoka: 13, avg_loss: (1.3313222474254776+0j)\n",
      "Epoka: 14, avg_loss: (1.328281616946561+0j)\n",
      "Epoka: 15, avg_loss: (1.325250514214541+0j)\n",
      "Epoka: 16, avg_loss: (1.3222289637419797+0j)\n",
      "Epoka: 17, avg_loss: (1.3192169897817427+0j)\n",
      "Epoka: 18, avg_loss: (1.3162146163217154+0j)\n",
      "Epoka: 19, avg_loss: (1.3132218670794322+0j)\n",
      "Epoka: 20, avg_loss: (1.3102387654965866+0j)\n",
      "Epoka: 21, avg_loss: (1.3072653347334502+0j)\n",
      "Epoka: 22, avg_loss: (1.304301597663202+0j)\n",
      "Epoka: 23, avg_loss: (1.3013475768661666+0j)\n",
      "Epoka: 24, avg_loss: (1.2984032946239592+0j)\n",
      "Epoka: 25, avg_loss: (1.2954687729135737+0j)\n",
      "Epoka: 26, avg_loss: (1.2925440334013845+0j)\n",
      "Epoka: 27, avg_loss: (1.2896290974370783+0j)\n",
      "Epoka: 28, avg_loss: (1.2867239860475437+0j)\n",
      "Epoka: 29, avg_loss: (1.283828719930698+0j)\n",
      "Epoka: 30, avg_loss: (1.2809433194492665+0j)\n",
      "Epoka: 31, avg_loss: (1.2780678046245342+0j)\n",
      "Epoka: 32, avg_loss: (1.2752021951300572+0j)\n",
      "Epoka: 33, avg_loss: (1.272346510285351+0j)\n",
      "Epoka: 34, avg_loss: (1.2695007690495788+0j)\n",
      "Epoka: 35, avg_loss: (1.2666649900152114+0j)\n",
      "Epoka: 36, avg_loss: (1.2638391914017009+0j)\n",
      "Epoka: 37, avg_loss: (1.2610233910491662+0j)\n",
      "Epoka: 38, avg_loss: (1.2582176064120827+0j)\n",
      "Epoka: 39, avg_loss: (1.2554218545530078+0j)\n",
      "Epoka: 40, avg_loss: (1.2526361521363412+0j)\n",
      "Epoka: 41, avg_loss: (1.2498605154221119+0j)\n",
      "Epoka: 42, avg_loss: (1.247094960259843+0j)\n",
      "Epoka: 43, avg_loss: (1.2443395020824393+0j)\n",
      "Epoka: 44, avg_loss: (1.2415941559001757+0j)\n",
      "Epoka: 45, avg_loss: (1.2388589362947326+0j)\n",
      "Epoka: 46, avg_loss: (1.236133857413335+0j)\n",
      "Epoka: 47, avg_loss: (1.2334189329629552+0j)\n",
      "Epoka: 48, avg_loss: (1.2307141762046514+0j)\n",
      "Epoka: 49, avg_loss: (1.228019599947971+0j)\n",
      "Epoka: 0, avg_loss: (0.9734320509347443+0j)\n",
      "Epoka: 1, avg_loss: (0.9719522257225734+0j)\n",
      "Epoka: 2, avg_loss: (0.9704805086852686+0j)\n",
      "Epoka: 3, avg_loss: (0.9690168631346417+0j)\n",
      "Epoka: 4, avg_loss: (0.9675612523439375+0j)\n",
      "Epoka: 5, avg_loss: (0.9661136395522576+0j)\n",
      "Epoka: 6, avg_loss: (0.9646739879689118+0j)\n",
      "Epoka: 7, avg_loss: (0.9632422607777141+0j)\n",
      "Epoka: 8, avg_loss: (0.9618184211412043+0j)\n",
      "Epoka: 9, avg_loss: (0.9604024322048159+0j)\n",
      "Epoka: 10, avg_loss: (0.9589942571009703+0j)\n",
      "Epoka: 11, avg_loss: (0.95759385895311+0j)\n",
      "Epoka: 12, avg_loss: (0.956201200879669+0j)\n",
      "Epoka: 13, avg_loss: (0.9548162459979734+0j)\n",
      "Epoka: 14, avg_loss: (0.9534389574280858+0j)\n",
      "Epoka: 15, avg_loss: (0.952069298296578+0j)\n",
      "Epoka: 16, avg_loss: (0.9507072317402429+0j)\n",
      "Epoka: 17, avg_loss: (0.9493527209097459+0j)\n",
      "Epoka: 18, avg_loss: (0.9480057289732029+0j)\n",
      "Epoka: 19, avg_loss: (0.9466662191197095+0j)\n",
      "Epoka: 20, avg_loss: (0.9453341545627927+0j)\n",
      "Epoka: 21, avg_loss: (0.9440094985438127+0j)\n",
      "Epoka: 22, avg_loss: (0.9426922143352912+0j)\n",
      "Epoka: 23, avg_loss: (0.9413822652441849+0j)\n",
      "Epoka: 24, avg_loss: (0.9400796146150968+0j)\n",
      "Epoka: 25, avg_loss: (0.9387842258334205+0j)\n",
      "Epoka: 26, avg_loss: (0.9374960623284315+0j)\n",
      "Epoka: 27, avg_loss: (0.9362150875763138+0j)\n",
      "Epoka: 28, avg_loss: (0.9349412651031237+0j)\n",
      "Epoka: 29, avg_loss: (0.9336745584876994+0j)\n",
      "Epoka: 30, avg_loss: (0.9324149313645087+0j)\n",
      "Epoka: 31, avg_loss: (0.9311623474264398+0j)\n",
      "Epoka: 32, avg_loss: (0.9299167704275264+0j)\n",
      "Epoka: 33, avg_loss: (0.9286781641856299+0j)\n",
      "Epoka: 34, avg_loss: (0.9274464925850464+0j)\n",
      "Epoka: 35, avg_loss: (0.9262217195790695+0j)\n",
      "Epoka: 36, avg_loss: (0.925003809192494+0j)\n",
      "Epoka: 37, avg_loss: (0.9237927255240613+0j)\n",
      "Epoka: 38, avg_loss: (0.9225884327488503+0j)\n",
      "Epoka: 39, avg_loss: (0.9213908951206157+0j)\n",
      "Epoka: 40, avg_loss: (0.9202000769740725+0j)\n",
      "Epoka: 41, avg_loss: (0.9190159427271192+0j)\n",
      "Epoka: 42, avg_loss: (0.9178384568830211+0j)\n",
      "Epoka: 43, avg_loss: (0.9166675840325289+0j)\n",
      "Epoka: 44, avg_loss: (0.9155032888559529+0j)\n",
      "Epoka: 45, avg_loss: (0.9143455361251834+0j)\n",
      "Epoka: 46, avg_loss: (0.9131942907056594+0j)\n",
      "Epoka: 47, avg_loss: (0.9120495175582906+0j)\n",
      "Epoka: 48, avg_loss: (0.9109111817413247+0j)\n",
      "Epoka: 49, avg_loss: (0.9097792484121665+0j)\n",
      "Epoka: 0, avg_loss: (0.8501658404315503+0j)\n",
      "Epoka: 1, avg_loss: (0.849317470430004+0j)\n",
      "Epoka: 2, avg_loss: (0.8484740381440705+0j)\n",
      "Epoka: 3, avg_loss: (0.8476355149110848+0j)\n",
      "Epoka: 4, avg_loss: (0.846801872186817+0j)\n",
      "Epoka: 5, avg_loss: (0.8459730815461128+0j)\n",
      "Epoka: 6, avg_loss: (0.8451491146835008+0j)\n",
      "Epoka: 7, avg_loss: (0.844329943413772+0j)\n",
      "Epoka: 8, avg_loss: (0.8435155396725359+0j)\n",
      "Epoka: 9, avg_loss: (0.8427058755167531+0j)\n",
      "Epoka: 10, avg_loss: (0.8419009231252372+0j)\n",
      "Epoka: 11, avg_loss: (0.8411006547991339+0j)\n",
      "Epoka: 12, avg_loss: (0.8403050429623821+0j)\n",
      "Epoka: 13, avg_loss: (0.8395140601621379+0j)\n",
      "Epoka: 14, avg_loss: (0.8387276790691879+0j)\n",
      "Epoka: 15, avg_loss: (0.8379458724783292+0j)\n",
      "Epoka: 16, avg_loss: (0.837168613308737+0j)\n",
      "Epoka: 17, avg_loss: (0.8363958746042965+0j)\n",
      "Epoka: 18, avg_loss: (0.8356276295339272+0j)\n",
      "Epoka: 19, avg_loss: (0.8348638513918728+0j)\n",
      "Epoka: 20, avg_loss: (0.8341045135979767+0j)\n",
      "Epoka: 21, avg_loss: (0.8333495896979378+0j)\n",
      "Epoka: 22, avg_loss: (0.8325990533635402+0j)\n",
      "Epoka: 23, avg_loss: (0.8318528783928639+0j)\n",
      "Epoka: 24, avg_loss: (0.8311110387104818+0j)\n",
      "Epoka: 25, avg_loss: (0.8303735083676317+0j)\n",
      "Epoka: 26, avg_loss: (0.8296402615423641+0j)\n",
      "Epoka: 27, avg_loss: (0.828911272539687+0j)\n",
      "Epoka: 28, avg_loss: (0.8281865157916755+0j)\n",
      "Epoka: 29, avg_loss: (0.8274659658575717+0j)\n",
      "Epoka: 30, avg_loss: (0.8267495974238688+0j)\n",
      "Epoka: 31, avg_loss: (0.8260373853043734+0j)\n",
      "Epoka: 32, avg_loss: (0.8253293044402467+0j)\n",
      "Epoka: 33, avg_loss: (0.8246253299000426+0j)\n",
      "Epoka: 34, avg_loss: (0.8239254368797201+0j)\n",
      "Epoka: 35, avg_loss: (0.8232296007026353+0j)\n",
      "Epoka: 36, avg_loss: (0.8225377968195253+0j)\n",
      "Epoka: 37, avg_loss: (0.8218500008084821+0j)\n",
      "Epoka: 38, avg_loss: (0.8211661883748949+0j)\n",
      "Epoka: 39, avg_loss: (0.8204863353513897+0j)\n",
      "Epoka: 40, avg_loss: (0.8198104176977569+0j)\n",
      "Epoka: 41, avg_loss: (0.8191384115008514+0j)\n",
      "Epoka: 42, avg_loss: (0.8184702929744938+0j)\n",
      "Epoka: 43, avg_loss: (0.817806038459352+0j)\n",
      "Epoka: 44, avg_loss: (0.8171456244228019+0j)\n",
      "Epoka: 45, avg_loss: (0.8164890274587902+0j)\n",
      "Epoka: 46, avg_loss: (0.8158362242876773+0j)\n",
      "Epoka: 47, avg_loss: (0.815187191756058+0j)\n",
      "Epoka: 48, avg_loss: (0.8145419068365949+0j)\n",
      "Epoka: 49, avg_loss: (0.8139003466278103+0j)\n",
      "Best Mean: 8.800993165604883\n",
      "Best Std Deviation: 41.787874283677695\n",
      "Best Average Loss: (0.6898232796664505+0j)\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 20  # Adjust this as needed\n",
    "best_mean = None\n",
    "best_std_deviation = None\n",
    "best_loss = float('inf')\n",
    "training_data = np.hstack((x_train, y_train.astype(int))).tolist()\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    # losowe wartości dla mean i odchylenia\n",
    "    mean = np.random.uniform(5, 150)\n",
    "    std_deviation = np.random.uniform(2, 50)\n",
    "\n",
    "    network = initialize_network(n_inputs, hidden_layers, n_outputs, std_deviation, mean)\n",
    "    output_loss = train_network(network, training_data, 0.9, 50, 1)\n",
    "\n",
    "    if output_loss < best_loss:\n",
    "        best_mean = mean\n",
    "        best_std_deviation = std_deviation\n",
    "        best_loss = output_loss\n",
    "\n",
    "print(\"Best Mean:\", best_mean)\n",
    "print(\"Best Std Deviation:\", best_std_deviation)\n",
    "print(\"Best Average Loss:\", best_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka: 0, avg_loss: (0.7194916328804951+0j)\n",
      "Epoka: 1, avg_loss: (0.7194343672045368+0j)\n",
      "Epoka: 2, avg_loss: (0.7193772226732709+0j)\n",
      "Epoka: 3, avg_loss: (0.7193201990002579+0j)\n",
      "Epoka: 4, avg_loss: (0.7192632958998205+0j)\n",
      "Epoka: 5, avg_loss: (0.7192065130870355+0j)\n",
      "Epoka: 6, avg_loss: (0.7191498502777377+0j)\n",
      "Epoka: 7, avg_loss: (0.7190933071885155+0j)\n",
      "Epoka: 8, avg_loss: (0.7190368835367056+0j)\n",
      "Epoka: 9, avg_loss: (0.718980579040395+0j)\n",
      "Epoka: 10, avg_loss: (0.7189243934184183+0j)\n",
      "Epoka: 11, avg_loss: (0.7188683263903519+0j)\n",
      "Epoka: 12, avg_loss: (0.7188123776765174+0j)\n",
      "Epoka: 13, avg_loss: (0.7187565469979719+0j)\n",
      "Epoka: 14, avg_loss: (0.7187008340765152+0j)\n",
      "Epoka: 15, avg_loss: (0.7186452386346794+0j)\n",
      "Epoka: 16, avg_loss: (0.718589760395731+0j)\n",
      "Epoka: 17, avg_loss: (0.7185343990836675+0j)\n",
      "Epoka: 18, avg_loss: (0.7184791544232184+0j)\n",
      "Epoka: 19, avg_loss: (0.7184240261398339+0j)\n",
      "Epoka: 20, avg_loss: (0.7183690139596949+0j)\n",
      "Epoka: 21, avg_loss: (0.718314117609703+0j)\n",
      "Epoka: 22, avg_loss: (0.7182593368174783+0j)\n",
      "Epoka: 23, avg_loss: (0.7182046713113632+0j)\n",
      "Epoka: 24, avg_loss: (0.7181501208204134+0j)\n",
      "Epoka: 25, avg_loss: (0.7180956850744016+0j)\n",
      "Epoka: 26, avg_loss: (0.7180413638038098+0j)\n",
      "Epoka: 27, avg_loss: (0.7179871567398309+0j)\n",
      "Epoka: 28, avg_loss: (0.7179330636143686+0j)\n",
      "Epoka: 29, avg_loss: (0.7178790841600271+0j)\n",
      "Epoka: 30, avg_loss: (0.7178252181101189+0j)\n",
      "Epoka: 31, avg_loss: (0.7177714651986578+0j)\n",
      "Epoka: 32, avg_loss: (0.7177178251603563+0j)\n",
      "Epoka: 33, avg_loss: (0.717664297730624+0j)\n",
      "Epoka: 34, avg_loss: (0.7176108826455673+0j)\n",
      "Epoka: 35, avg_loss: (0.7175575796419856+0j)\n",
      "Epoka: 36, avg_loss: (0.7175043884573705+0j)\n",
      "Epoka: 37, avg_loss: (0.7174513088299028+0j)\n",
      "Epoka: 38, avg_loss: (0.7173983404984513+0j)\n",
      "Epoka: 39, avg_loss: (0.7173454832025682+0j)\n",
      "Epoka: 40, avg_loss: (0.7172927366824929+0j)\n",
      "Epoka: 41, avg_loss: (0.7172401006791436+0j)\n",
      "Epoka: 42, avg_loss: (0.7171875749341184+0j)\n",
      "Epoka: 43, avg_loss: (0.7171351591896935+0j)\n",
      "Epoka: 44, avg_loss: (0.7170828531888219+0j)\n",
      "Epoka: 45, avg_loss: (0.7170306566751272+0j)\n",
      "Epoka: 46, avg_loss: (0.7169785693929067+0j)\n",
      "Epoka: 47, avg_loss: (0.716926591087127+0j)\n",
      "Epoka: 48, avg_loss: (0.7168747215034244+0j)\n",
      "Epoka: 49, avg_loss: (0.7168229603880951+0j)\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "training_data = np.hstack((x_train, y_train.astype(int))).tolist()\n",
    "n_inputs = len(training_data[0]) - 1\n",
    "\n",
    "n_inputs = 13\n",
    "hidden_layers = [5,5,3]\n",
    "n_outputs = 1\n",
    "std_deviation = 41.78\n",
    "mean = 8.801\n",
    "network = initialize_network(n_inputs, hidden_layers, n_outputs, std_deviation, mean)\n",
    "\n",
    "# network = initialize_network(n_inputs, [5,5,5], 1)\n",
    "output_data = train_network(network, training_data, 0.5, 50, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7213114754098361\n",
      "Confusion: [[24  9]\n",
      " [ 8 20]]\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74        33\n",
      "           1       0.69      0.71      0.70        28\n",
      "\n",
      "    accuracy                           0.72        61\n",
      "   macro avg       0.72      0.72      0.72        61\n",
      "weighted avg       0.72      0.72      0.72        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def min_max_scale(value, min_val, max_val):\n",
    "    return (value - min_val) / (max_val - min_val)\n",
    "\n",
    "def predict(data):\n",
    "\toutputs = []\n",
    "\ty_preds = []\n",
    "\n",
    "\tfor row in data:\n",
    "\t\toutput = forward_propagate(network, row)[0].real\n",
    "\t\toutputs.append(output)\n",
    "\n",
    "\tmin_output = min(outputs)\n",
    "\tmax_output = max(outputs)\n",
    "\n",
    "\tfor output in outputs:\n",
    "\t\tscaled_output = min_max_scale(output, min_output, max_output)\n",
    "\t\t# print(scaled_output)\n",
    "\t\tbinary_prediction = 1 if scaled_output >= 0.5 else 0\n",
    "\t\ty_preds.append(binary_prediction)\n",
    "\n",
    "\treturn np.array(y_preds)\n",
    "\n",
    "# def predict(data):\n",
    "# \toutputs = []\n",
    "# \ty_preds = []\n",
    "# \tfor row in data:\n",
    "# \t\toutput = forward_propagate(network, row)[0].real\n",
    "# \t\toutputs.append(output)\n",
    "# \t\t# print(output)\n",
    "# \t\tbinary_prediction = 1 if output >= 0.65 else 0\n",
    "# \t\ty_preds.append(binary_prediction)\n",
    "#\n",
    "# \treturn np.array(y_preds)\n",
    "#Ocena modelu\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "y_pred = predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion: {confusion}')\n",
    "print(f'Report: {report}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}