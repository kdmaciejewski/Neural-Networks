{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\krzys\\desktop\\pythonproject\\againterpreter\\lib\\site-packages\\pandas\\core\\generic.py:6392: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n0     63    1   1       145   233    1        2      150      0      2.3   \n1     67    1   4       160   286    0        2      108      1      1.5   \n2     67    1   4       120   229    0        2      129      1      2.6   \n3     37    1   3       130   250    0        0      187      0      3.5   \n4     41    0   2       130   204    0        2      172      0      1.4   \n..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n298   45    1   1       110   264    0        0      132      0      1.2   \n299   68    1   4       144   193    1        0      141      0      3.4   \n300   57    1   4       130   131    0        0      115      1      1.2   \n301   57    0   2       130   236    0        2      174      0      0.0   \n302   38    1   3       138   175    0        0      173      0      0.0   \n\n     slope   ca  thal  \n0        3  0.0   6.0  \n1        2  3.0   3.0  \n2        2  2.0   7.0  \n3        3  0.0   3.0  \n4        1  0.0   3.0  \n..     ...  ...   ...  \n298      2  0.0   7.0  \n299      2  2.0   7.0  \n300      2  1.0   7.0  \n301      2  1.0   3.0  \n302      1  0.0   3.0  \n\n[303 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trestbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalach</th>\n      <th>exang</th>\n      <th>oldpeak</th>\n      <th>slope</th>\n      <th>ca</th>\n      <th>thal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>1</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>2</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>67</td>\n      <td>1</td>\n      <td>4</td>\n      <td>160</td>\n      <td>286</td>\n      <td>0</td>\n      <td>2</td>\n      <td>108</td>\n      <td>1</td>\n      <td>1.5</td>\n      <td>2</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67</td>\n      <td>1</td>\n      <td>4</td>\n      <td>120</td>\n      <td>229</td>\n      <td>0</td>\n      <td>2</td>\n      <td>129</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>37</td>\n      <td>1</td>\n      <td>3</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>0</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41</td>\n      <td>0</td>\n      <td>2</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>2</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>45</td>\n      <td>1</td>\n      <td>1</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>0</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>68</td>\n      <td>1</td>\n      <td>4</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>0</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>57</td>\n      <td>1</td>\n      <td>4</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>0</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>0</td>\n      <td>2</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>2</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>38</td>\n      <td>1</td>\n      <td>3</td>\n      <td>138</td>\n      <td>175</td>\n      <td>0</td>\n      <td>0</td>\n      <td>173</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 13 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import danych i zastąpienie brakujących wartości modą\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "heart_disease = fetch_ucirepo(id=45)\n",
    "\n",
    "X = heart_disease.data.features\n",
    "Y = heart_disease.data.targets\n",
    "\n",
    "# print(heart_disease.variables)\n",
    "\n",
    "X.fillna({'ca': X['ca'].median(), 'thal': X['thal'].mode()[0]}, inplace=True)\n",
    "\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70833333 1.         0.         ... 1.         0.         0.75      ]\n",
      " [0.79166667 1.         1.         ... 0.5        1.         0.        ]\n",
      " [0.79166667 1.         1.         ... 0.5        0.66666667 1.        ]\n",
      " ...\n",
      " [0.58333333 1.         1.         ... 0.5        0.33333333 1.        ]\n",
      " [0.58333333 0.         0.33333333 ... 0.5        0.33333333 0.        ]\n",
      " [0.1875     1.         0.66666667 ... 0.         0.         0.        ]]\n",
      "(303, 13)\n",
      "(303, 1)\n"
     ]
    }
   ],
   "source": [
    "#model klasyfikacji z regresją logistyczną\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for index, row in Y.iterrows():\n",
    "    if row[0] != 0:\n",
    "        row[0] = 1 #jeżeli nie ma klasy 0 to ma klasę 1\n",
    "\n",
    "y = Y.to_numpy()\n",
    "X = (X-X.min())/(X.max()-X.min())\n",
    "x = X.to_numpy()\n",
    "\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size= 0.2)\n",
    "\n",
    "number_of_features = 13\n",
    "#losowa inicjalizacja wag\n",
    "\n",
    "weights = np.random.uniform(0.0, 100.0, size=number_of_features)\n",
    "bias= np.random.rand(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z/200))\n",
    "    # return 1 / (1 + np.exp(-(z-200)))\n",
    "\n",
    "def neuron_calculation(X, weights, bias):\n",
    "    sig_arg = np.dot(X, weights) + bias\n",
    "    return sigmoid(sig_arg)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8034703  0.75774583 0.79395349 0.75838567 0.77948275 0.77525362\n",
      " 0.81083218 0.70302536 0.76088332 0.80245412 0.69849167 0.70818971\n",
      " 0.81202898 0.85518255 0.80472808 0.72004492 0.65956251 0.70590109\n",
      " 0.6935855  0.75999214 0.60975632 0.80420863 0.78350356 0.85698294\n",
      " 0.747237   0.633886   0.60920879 0.77403382 0.78883902 0.83157676\n",
      " 0.78746444 0.61666697 0.70772551 0.7228303  0.66401601 0.76226734\n",
      " 0.80606239 0.67852551 0.70264875 0.66084189 0.79416869 0.69935089\n",
      " 0.67704422 0.84925633 0.79228736 0.78436363 0.78996299 0.75489577\n",
      " 0.74616386 0.75746696 0.63127119 0.77201607 0.80606594 0.84704067\n",
      " 0.74404026 0.79400223 0.78637965 0.76624212 0.673589   0.78498651\n",
      " 0.85362887 0.86677345 0.69061662 0.87172641 0.69738226 0.68922768\n",
      " 0.84196411 0.66206748 0.77192631 0.78941178 0.62261005 0.79573041\n",
      " 0.62856454 0.88273357 0.63242911 0.70769064 0.71878961 0.68773216\n",
      " 0.67535622 0.83371064 0.59724566 0.63456928 0.80543532 0.83425308\n",
      " 0.76767768 0.78014774 0.82795483 0.80639345 0.71867589 0.67707679\n",
      " 0.78829553 0.76225859 0.7949375  0.68664624 0.62224081 0.78160391\n",
      " 0.68965721 0.69475013 0.77757844 0.69424936 0.84158059 0.83766035\n",
      " 0.65284295 0.79997017 0.74375274 0.78890187 0.72158254 0.79163741\n",
      " 0.78208266 0.81295125 0.76663838 0.79930625 0.78089227 0.78668461\n",
      " 0.71268551 0.85722033 0.81506426 0.66193167 0.87375257 0.70788371\n",
      " 0.83459739 0.68157143 0.6879272  0.77807776 0.6286251  0.79235983\n",
      " 0.67962337 0.78658588 0.69893461 0.65835072 0.7885531  0.68840283\n",
      " 0.67425656 0.77554282 0.7774686  0.79238166 0.65932043 0.70631645\n",
      " 0.63289562 0.63749863 0.8853614  0.76269852 0.6781253  0.71729678\n",
      " 0.78259457 0.80321547 0.66931764 0.77003633 0.68877406 0.77096741\n",
      " 0.63342701 0.75123671 0.79253913 0.65498048 0.87004336 0.71955387\n",
      " 0.69412736 0.70699631 0.72312784 0.61999086 0.77275547 0.68384036\n",
      " 0.6333809  0.70563557 0.70677833 0.68757985 0.71696355 0.74139707\n",
      " 0.71592912 0.84008034 0.67610576 0.66226695 0.7109936  0.69292688\n",
      " 0.74399543 0.61610993 0.66946209 0.69695242 0.68239988 0.63527188\n",
      " 0.66097719 0.82139945 0.82138763 0.74379599 0.69379739 0.66739381\n",
      " 0.7098351  0.68511725 0.74034983 0.79238106 0.79238986 0.78123459\n",
      " 0.73217041 0.69911678 0.64959874 0.65996616 0.82919351 0.69512234\n",
      " 0.80094845 0.81183115 0.68963463 0.70033041 0.62871891 0.68980024\n",
      " 0.70254825 0.62433197 0.80739989 0.73413047 0.87064041 0.78020157\n",
      " 0.65141959 0.7391627  0.73105313 0.81221326 0.78477835 0.70519131\n",
      " 0.70960069 0.64525641 0.6293509  0.75157545 0.78761356 0.80559262\n",
      " 0.79855148 0.7391801  0.76450921 0.77861253 0.7771086  0.66844828\n",
      " 0.76792971 0.78927245 0.76320279 0.7365837  0.65144502 0.82917939\n",
      " 0.7877477  0.80999009 0.7323682  0.85399684 0.7035248  0.7623098\n",
      " 0.70521475 0.79546013]\n"
     ]
    }
   ],
   "source": [
    "predicted_probabilities = neuron_calculation(x_train, weights, bias)\n",
    "\n",
    "print(predicted_probabilities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# ta funkcja kosztu ma\n",
    "def loss_fun(y, y_pred):\n",
    "    epsilon = 1e-15  # zapobieganie log(0)\n",
    "    loss = - (y * np.log(y_pred + epsilon) + (1 - y) * np.log(1 - y_pred + epsilon))\n",
    "    # loss = - (y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred ))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def update_weights(X, y, y_pred, weights, bias, learning_rate):\n",
    "    arX = np.squeeze(np.asarray(X))\n",
    "    ary = np.squeeze(np.asarray((y_pred - y)))\n",
    "    gradient_weights = np.dot(arX, ary)\n",
    "    gradient_bias = np.sum(y_pred - y)\n",
    "    #aktualizacja wag\n",
    "    weights -= learning_rate * gradient_weights\n",
    "    bias -= learning_rate * gradient_bias\n",
    "\n",
    "    return weights, bias"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[26.99201174 43.56794124  1.38222621 58.12122119 92.64274237 85.79376628\n",
      " 96.36466482 80.04343412 26.60320607  3.50027929  8.69026012 28.02512599\n",
      "  0.860178  ]\n"
     ]
    }
   ],
   "source": [
    "# print(np.mean(loss_fun(y_train[1], sigmoid(np.dot(x_train[1], weights) + bias))))\n",
    "# print(loss_fun(y_train[1], sigmoid(np.dot(x_train[1], weights) + bias)))\n",
    "print(type(x_train))\n",
    "print(weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Average loss = [0.80199707]\n",
      "Epoch 100: Average loss = [0.4176474]\n",
      "Epoch 200: Average loss = [0.38366244]\n",
      "Epoch 300: Average loss = [0.37009379]\n",
      "Epoch 400: Average loss = [0.36273616]\n",
      "Epoch 500: Average loss = [0.35812195]\n",
      "Epoch 600: Average loss = [0.35495125]\n",
      "Epoch 700: Average loss = [0.35263111]\n",
      "Epoch 800: Average loss = [0.3508561]\n",
      "Epoch 900: Average loss = [0.34945406]\n",
      "Epoch 1000: Average loss = [0.34832052]\n",
      "Epoch 1100: Average loss = [0.34738807]\n",
      "Epoch 1200: Average loss = [0.3466109]\n",
      "Epoch 1300: Average loss = [0.34595645]\n",
      "Epoch 1400: Average loss = [0.34540077]\n",
      "Epoch 1500: Average loss = [0.3449257]\n",
      "Epoch 1600: Average loss = [0.34451717]\n",
      "Epoch 1700: Average loss = [0.34416405]\n",
      "Epoch 1800: Average loss = [0.34385741]\n",
      "Epoch 1900: Average loss = [0.34359004]\n",
      "Trained Weights: [-147.50888429  195.15165623  319.06185165  414.63414838  153.2702821\n",
      " -177.03797546  135.73626987 -462.85866607  165.28643887  485.96693823\n",
      "  258.19407125  775.80666933  295.97479826]\n",
      "Trained Bias: [-754.15876768]\n"
     ]
    }
   ],
   "source": [
    "num_of_features = x_train.shape[1]\n",
    "# hiperparametry\n",
    "learning_rate = 0.3\n",
    "epochs = 2000\n",
    "prev_loss = 1\n",
    "avg_loss = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss_arr = []\n",
    "    for i in range(len(x_train)):\n",
    "        X = x_train[i]\n",
    "        y = y_train[i]\n",
    "        y_pred = sigmoid(np.dot(X, weights) + bias)\n",
    "        loss = loss_fun(y, y_pred)\n",
    "        loss_arr.append(loss)\n",
    "        weights, bias = update_weights(X, y, y_pred, weights, bias, learning_rate)\n",
    "\n",
    "        binary_prediction = 1 if y_pred >= 0.5 else 0\n",
    "    if epoch % 100 == 0:\n",
    "        prev_loss = avg_loss\n",
    "        avg_loss = sum(loss_arr) / len(loss_arr)\n",
    "        print(f\"Epoch {epoch}: Average loss = {avg_loss}\")\n",
    "        #if (1-(avg_loss/prev_loss))*100 < 2: break #zbyt mała zmiana f.kosztu procentowo\n",
    "\n",
    "print(\"Trained Weights:\", weights)\n",
    "print(\"Trained Bias:\", bias)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def predict(x_data):\n",
    "    y_preds = []\n",
    "    for i in range(len(x_data)):\n",
    "        X = x_data[i]\n",
    "        y_pred = sigmoid(np.dot(X, weights) + bias)\n",
    "        print(y_pred)\n",
    "        binary_prediction = 1 if y_pred >= 0.5 else 0\n",
    "        y_preds.append(binary_prediction)\n",
    "    return np.array(y_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26137979]\n",
      "[0.3235555]\n",
      "[0.72030682]\n",
      "[0.08811941]\n",
      "[0.04674313]\n",
      "[0.04761401]\n",
      "[0.66470726]\n",
      "[0.02739183]\n",
      "[0.04486012]\n",
      "[0.99632406]\n",
      "[0.94853401]\n",
      "[0.98178307]\n",
      "[0.05366666]\n",
      "[0.21845639]\n",
      "[0.88876231]\n",
      "[0.29028641]\n",
      "[0.03715324]\n",
      "[0.05396505]\n",
      "[0.01617608]\n",
      "[0.97888807]\n",
      "[0.93006019]\n",
      "[0.9775171]\n",
      "[0.12713025]\n",
      "[0.74286826]\n",
      "[0.14373727]\n",
      "[0.21336072]\n",
      "[0.00983207]\n",
      "[0.12097168]\n",
      "[0.17122704]\n",
      "[0.79362191]\n",
      "[0.18026331]\n",
      "[0.70255519]\n",
      "[0.9584979]\n",
      "[0.04924141]\n",
      "[0.17963655]\n",
      "[0.4889384]\n",
      "[0.98211885]\n",
      "[0.0409725]\n",
      "[0.0289731]\n",
      "[0.05353171]\n",
      "[0.8752077]\n",
      "[0.86750771]\n",
      "[0.97041881]\n",
      "[0.04877747]\n",
      "[0.45810077]\n",
      "[0.10730786]\n",
      "[0.7780691]\n",
      "[0.04029871]\n",
      "[0.94918904]\n",
      "[0.11247264]\n",
      "[0.17917382]\n",
      "[0.9411317]\n",
      "[0.99403535]\n",
      "[0.9520936]\n",
      "[0.99657562]\n",
      "[0.91886855]\n",
      "[0.99089492]\n",
      "[0.02630096]\n",
      "[0.95349865]\n",
      "[0.9859725]\n",
      "[0.78916464]\n",
      "Accuracy: 0.8524590163934426\n",
      "Confusion: [[28  4]\n",
      " [ 5 24]]\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86        32\n",
      "           1       0.86      0.83      0.84        29\n",
      "\n",
      "    accuracy                           0.85        61\n",
      "   macro avg       0.85      0.85      0.85        61\n",
      "weighted avg       0.85      0.85      0.85        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ocena modelu\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "y_pred = predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion: {confusion}')\n",
    "print(f'Report: {report}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8512396694214877\n",
      "Confusion: [[111  14]\n",
      " [ 22  95]]\n",
      "Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       125\n",
      "           1       0.87      0.81      0.84       117\n",
      "\n",
      "    accuracy                           0.85       242\n",
      "   macro avg       0.85      0.85      0.85       242\n",
      "weighted avg       0.85      0.85      0.85       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ocena modelu\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "y_pred = predict(x_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "confusion = confusion_matrix(y_train, y_pred)\n",
    "report = classification_report(y_train, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion: {confusion}')\n",
    "print(f'Report: {report}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}